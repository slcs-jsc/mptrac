{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MPTRAC!","text":"<p>Massive-Parallel Trajectory Calculations (MPTRAC) is a Lagrangian particle dispersion model to analyze atmospheric transport processes in the free troposphere and stratosphere. Leveraging high-performance computing techniques, MPTRAC efficiently handles large-scale trajectory simulations, making it a powerful tool for both research and operational applications.</p> <p></p>"},{"location":"#features","title":"Features","text":"<p>MPTRAC is a powerful tool for atmospheric Lagrangian transport simulations, offering a wide range of features to enhance accuracy, performance, and usability:</p> <ul> <li> <p>Advanced Trajectory Calculations: MPTRAC calculates air parcel     trajectories by solving the kinematic equation of motion using     horizontal wind and vertical velocity fields from global     reanalyses or forecast datasets, enabling precise tracking of     atmospheric transport processes in the free troposphere and     stratosphere.</p> </li> <li> <p>Stochastic Perturbation and Mixing: Mesoscale diffusion and     subgrid-scale wind fluctuations are simulated using the Langevin     equation, introducing stochastic perturbations to trajectories. An     inter-parcel exchange module represents mixing of air between     neighboring particles, capturing realistic atmospheric dispersion.</p> </li> <li> <p>Comprehensive Process Modeling: MPTRAC includes modules to     simulate convection, sedimentation, exponential decay, gas and     aqueous phase chemistry, and wet and dry deposition, allowing for     accurate modeling of physical and chemical transformations.</p> </li> <li> <p>Meteorological Data Pre-Processing: The model pre-processes     meteorological data to estimate variables such as boundary layer     height, convective available potential energy (CAPE), geopotential     heights, potential vorticity, and tropopause data, ensuring     seamless integration with diverse datasets.</p> </li> <li> <p>Flexible Output and Visualization: MPTRAC supports various     output formats for particle trajectories, gridded fields, ensemble     statistics, vertical profiles, point samples, and station     data. Visualization interfaces with Gnuplot and ParaView make it     easy to analyze complex data.</p> </li> <li> <p>High-Performance Computing: The model employs hybrid     parallelization using MPI, OpenMP, and OpenACC, allowing efficient     utilization of resources from single workstations to HPC clusters     and GPU-based systems.</p> </li> <li> <p>Web-Based Accessibility: The new MPTRAC Web Runner provides an     intuitive, browser-based interface for running trajectory     simulations without local installation, making the tool more     accessible for educational, research, and operational users.</p> </li> <li> <p>Open Source and Community Driven: MPTRAC is distributed as     open-source software under the GNU General Public License (GPL),     promoting collaborative development and ensuring transparency.</p> </li> </ul> <p></p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To begin using MPTRAC, users can refer to the installation guide, which provides detailed steps for setting up the model on a local machine or HPC system. Once installed, the quick start guide offers a streamlined introduction to running basic simulations, helping new users become familiar with the model's core functionality and input structure.</p> <p>For those who prefer not to install any software locally, the MPTRAC Web Runner provides a convenient, browser-based interface for running trajectory simulations. This web tool is particularly useful for educational purposes, quick tests, and exploratory studies.</p> <p>We welcome contributions and collaboration from the research community. If you have questions, feedback, or require support, please feel free to reach out.</p>"},{"location":"#contact","title":"Contact","text":"<p>Dr. Lars Hoffmann</p> <p>J\u00fclich Supercomputing Centre, Forschungszentrum J\u00fclich, Germany</p> <p>e-mail: l.hoffmann@fz-juelich.de</p>"},{"location":"applications/","title":"Applications and workflows","text":""},{"location":"applications/#applications","title":"Applications","text":"<p>The MPTRAC model comes with a number of individual programs or applications. The most important app of MPTRAC is the tool trac, which is used to conduct the trajectory calculations.</p> <p>The apps met_map, met_prof, and met_zm can be used to extract global maps, vertical profiles, and zonal means from meteorological data. The app met_sample can be used to sample the meteo data at individual locations in space and time.</p> <p>The app atm_conv can be used to convert between different file formats of the particle data (ASCII, binary, netCDF). The app atm_dist can be used to calculate transport deviations between trajectory sets. The app atm_init can be used to create particle data files with initial trajectory seeds. The app atm_select can extract subsets of the particle data, like individual trajectories. The app atm_split can split sets of particles into larger sets, retaining their total mass. The app atm_stat calculates trajectory statistics, for example, the mean position of the air parcels.</p> <p>The tools day2doy, doy2day, jsec2time, and time2jsec are used for time conversion. In particular, they can be used to determine the day of the year (doy) for a given date and convert between a UTC time (YYYY-MM-DD, HH:MM:SS) and the absolute time in seconds since 2000-01-01, 00:00 UTC (the internal time coordinate of MPTRAC).</p> <p>The tools tropo and tropo_sample can be used to determine lapse rate statistics and to prepare and sample tropopause data files.</p> <p>Please see the list of files in the Doxygen manual for more information.</p>"},{"location":"applications/#workflows","title":"Workflows","text":"<p>The individual apps can be connected to more comprehensive simulation workflows by means of bash scripts.</p> <p>This is an example showing how <code>atm_init</code> and <code>atm_split</code> are used to initialize a simulation, and <code>trac</code> is used to calculate the trajectories:</p> <pre><code>#! /bin/bash\n\n# Setup...\ntrac=../src\n\n# Create directories...\nmkdir -p data plots\n\n# Set time range of simulations...\nt0=$($trac/time2jsec 2011 6 5 0 0 0 0)\nt1=$($trac/time2jsec 2011 6 8 0 0 0 0)\n\n# Set initial air parcel positions...\n$trac/atm_init trac.ctl data/atm_init.tab \\\n               INIT_T0 $t0 INIT_T1 $t0 \\\n               INIT_Z0 10.0 INIT_Z1 10.0 \\\n               INIT_LON0 -72.117 INIT_LON1 -72.117 \\\n               INIT_LAT0 -40.59 INIT_LAT1 -40.59\n\n# Split air parcels...\n$trac/atm_split trac.ctl data/atm_init.tab data/atm_split.tab \\\n                SPLIT_N 10000 SPLIT_M 1e9 SPLIT_DX 30.0 SPLIT_DZ 1.0\n\n# Calculate trajectories...\necho \"data\" &gt; data/dirlist\n$trac/trac data/dirlist trac.ctl atm_split.tab \\\n           ATM_BASENAME atm GRID_BASENAME grid\n</code></pre> <p>Please see the page on control parameters for more information.</p>"},{"location":"code-development/","title":"Code development","text":"<p>Please follow these guidelines when developing new code for MPTRAC.</p>"},{"location":"code-development/#compilation","title":"Compilation","text":"<p>To remove old binaries, backup files, etc., and to clean up the source code directory:</p> <pre><code>    make clean\n</code></pre> <p>For faster compilation, you can use parallel compilation with <code>make</code>:</p> <pre><code>    make -j\n</code></pre> <p>To compile a specific binary (e.g., <code>trac</code>):</p> <pre><code>    make trac\n</code></pre> <p>You can change Makefile variables at the command line:</p> <pre><code>    make DEFINES=\"-DNP=100000\" GPU=1 STATIC=0\n</code></pre>"},{"location":"code-development/#testing","title":"Testing","text":"<p>Always run the full test suite to verify your code changes:</p> <pre><code>    make check\n</code></pre> <p>Do not run tests in parallel (i.e., avoid using the <code>-j</code> option with <code>make check</code>), as this may cause test failures to be missed.</p> <p>You can run only selected tests, e.g.:</p> <pre><code>    make trac_test\n</code></pre> <p>If a test fails, please carefully compare the test results with the reference data. The Linux tool <code>xxdiff</code> can be used to compare test data and reference data number by number. The graphing utility <code>gnuplot</code> can be used to visualize any differences. The reference data of a test should only be updated if the new test results are considered correct.</p>"},{"location":"code-development/#static-code-analysis","title":"Static code analysis","text":"<p>You can use static code analysis to automatically detect potential problems in the code:</p> <pre><code>    make cppcheck\n    make lizard\n</code></pre>"},{"location":"code-development/#coverage-testing","title":"Coverage testing","text":"<p>You can perform a coverage analysis to determine which parts of the code are covered by tests:</p> <pre><code>    make COV=1\n    make coverage\n</code></pre> <p>If you find that parts of the code are not covered by the coverage analysis, please consider adding a new test.</p>"},{"location":"code-development/#automated-testing-and-code-analysis","title":"Automated testing and code analysis","text":"<p>After committing revised code to the GitHub repository, please check the GitHub Actions page to see if the automated tests were successfully passed.</p> <p>Please also check the Codacy and Codecov websites for test results.</p> <p>Please check the nightly build website to see if the tests passed on the Juelich supercomputers, especially for the GPU code.</p> <p>Users at the J\u00fclich Supercomputing Centre can also check the test results at the ESM Buildbot.</p>"},{"location":"code-development/#code-formatting","title":"Code formatting","text":"<p>On Linux, use the <code>indent</code> tool to apply a selected formatting style to the source code:</p> <pre><code>    make indent\n</code></pre> <p>Only use <code>indent</code> if the code has been compiled correctly. You may need to run the <code>indent</code> command 2-3 times to achieve the desired formatting.</p>"},{"location":"code-development/#documentation","title":"Documentation","text":"<p>Please update the README file as needed.</p> <p>To update the user manual, use:</p> <pre><code>    make mkdocs\n</code></pre> <p>To update the Doxygen manual, use:</p> <pre><code>    make doxygen\n</code></pre>"},{"location":"code-development/#installation","title":"Installation","text":"<p>To copy the executables from the source directory to the <code>DESTDIR</code> directory (default <code>../bin/</code>):</p> <pre><code>    make install\n</code></pre> <p>To remove the executables from the installation directory:</p> <pre><code>    make uninstall\n</code></pre> <p>To package the current repository state into a zip file, including the compiled binaries, run:</p> <pre><code>    make dist\n</code></pre>"},{"location":"code-development/#releases","title":"Releases","text":"<p>A new release of MPTRAC is usually created every six months.</p> <p>To create a new release, first define a version tag (\"vX.Y\") in the local repository:</p> <pre><code>    gitk\n</code></pre> <p>Next, push the local tags to the remote repository on GitHub:</p> <pre><code>    git push --tags\n</code></pre> <p>Get a list of short log messages from the previous to the current version of the code:</p> <pre><code>    git log v1.1..v1.2 --oneline\n</code></pre> <p>Using the log messages, draft a new release on GitHub using the newly created tag.</p> <p>Check the Zenodo website to publish the new release and to get a DOI.</p> <p>Use the DOI to submit an entry to the JuSER publication database.</p>"},{"location":"code-development/#cleaning-the-git-repository","title":"Cleaning the git repository","text":"<p>Always test the following procedures on a fresh copy of the repository!</p> <p>You can completely remove files from the Git repository using <code>git-filter-repo</code>: https://github.com/newren/git-filter-repo</p> <p>Analyze the current git repository:</p> <pre><code>    git filter-repo --analyze\n    cd .git/filter-repo/analysis/\n    ls\n</code></pre> <p>Remove all files except for those that currently exist:</p> <pre><code>    git ls-files &gt;../paths-i-want.txt\n    git filter-repo --paths-from-file ../paths-i-want.txt\n</code></pre>"},{"location":"code-development/#further-reading","title":"Further reading","text":"<ul> <li> <p>Git Handbook</p> </li> <li> <p>GitHub Git Cheat Sheet</p> </li> </ul>"},{"location":"control-parameters/","title":"Control parameters","text":"<p>The MPTRAC applications are controlled either through a control parameter file or by specifying control parameters directly as command-line arguments. A comprehensive list of control parameters is available in the Doxygen manual.</p> <p>By default, if no values are explicitly provided, the applications will use predefined default values for most control parameters. However, it's important to carefully review the log output from the MPTRAC tools to ensure that the control parameters are indeed set as intended.</p>"},{"location":"control-parameters/#control-parameter-file","title":"Control parameter file","text":"<p>Example of a control parameter file:</p> <pre><code># Quantities...\nNQ = 3\nQNT_NAME[0] = t\nQNT_NAME[1] = u\nQNT_NAME[2] = v\n\n# Meteo data...\nMETBASE = meteo/ei\nDT_MET = 86400\n\n# Grid output...\nGRID_LON0 = -90\nGRID_LON1 = 60\nGRID_LAT0 = -60\nGRID_LAT1 = -15\nGRID_NX = 300\nGRID_NY = 90\n</code></pre> <p>Note that the blanks before and after the equal sign are mandatory. Array indices start counting from zero, i.e, <code>a[0]</code>, <code>a[1]</code>, ..., as in the C programming language. You can use a minus sign (<code>-</code>) to indicate that no control parameter file is being used.</p>"},{"location":"control-parameters/#command-line-arguments","title":"Command line arguments","text":"<p>Control parameters can also be specified via command line arguments:</p> <pre><code>./atm_init trac.ctl data/atm_init.tab \\\n               INIT_LON0 -72.117 INIT_LON1 -72.117 \\\n               INIT_LAT0 -40.59 INIT_LAT1 -40.59\n</code></pre> <p>Command line arguments take precedence over values provided in the control parameter file.</p>"},{"location":"diabatic-transport/","title":"Diabatic transport","text":""},{"location":"diabatic-transport/#set-up-for-diabatic-transport-calculations","title":"Set-up for diabatic transport calculations","text":"<p>For diabatic transport, MPTRAC loads the fields \\(\\dot{\\zeta}\\), \\(\\zeta\\), and \\(p\\) in the original \\(\\eta\\) hybrid coordinate system from the CLaMS dataset. This approach avoids additional interpolation from \\(\\zeta\\) to \\(p\\). However, other fields remain in pressure coordinates since several MPTRAC modules require a pressure-based formulation.</p> <p>To ensure compatibility, \\(\\zeta\\) and \\(p\\) are converted back and forth before and after advection. Consequently, vertical model pressure levels must be explicitly defined. The following configuration is required for proper reading and transformation of CLaMS data:</p> <pre><code>MET_CLAMS = 1\nMET_VERT_COORD = 1\nMET_PRESS_LEVEL_DEF = 0\n</code></pre> <p>To enable vertical advection in \\(\\zeta\\) coordinates with diabatic transport, set the following parameters and include \\(\\zeta\\) as an atmospheric quantity:</p> <pre><code>ADVECT_VERT_COORD = 1\nNQ = 1\nQNT_NAME[0] = zeta\n</code></pre>"},{"location":"diabatic-transport/#predefined-pressure-level-sets","title":"Predefined pressure level sets","text":"<p>The <code>MET_PRESS_LEVEL_DEF</code> parameter allows selection from several predefined vertical pressure level sets, based on ECMWF model level definitions. Additional near-surface levels have been added (down to ~1045 hPa) to reduce extrapolation errors.</p> <p>By default, <code>MET_PRESS_LEVEL_DEF = -1</code>, meaning predefined sets are ignored. For ERA5 data, it is recommended to use set 6.</p> MET_PRESS_LEVEL_DEF Name bottom top number of levels 0 L137 1044.45 hPa 0.02 hPa 138 1 L91 1044.45 hPa 0.02 hPa 92 2 L60 1044.45 hPa 0.01 hPa 60 3 L137 1044.45 hPa 0.02 hPa 147 4 L91 1044.45 hPa 0.02 hPa 101 5 L60 1044.45 hPa 0.01 hPa 62 6 L137 1044.45 hPa 0.01 hPa 137 7 L60 1046.13 hPa 0.1 hPa 59"},{"location":"fortran-wrapper/","title":"Fortran wrapper","text":"<p>MPTRAC has been equiped with a wrapper to access the C functions from Fortran. The project started as a coding sprint in the natESM project LAGOOn.</p> <p>To integrate multi language programming with Fortran and C in a single program the ISO_C_BINDINGS module is since Fortran 2003 the standard approach that facilitates interoperability between the two languages. In Fortran, the compiler is informed with the BIND(C) attribute that a symbol shall be interoperable with C.</p>"},{"location":"fortran-wrapper/#compilation-and-testing","title":"Compilation and testing","text":"<p>To compile the Fortran wrapper, navigate to the <code>src</code> directory and run the following command:</p> <pre><code>$ make wrapper\n</code></pre> <p>To test the compiled wrapper, use the following command in the same directory:</p> <pre><code>$ make wrapper_test\n</code></pre>"},{"location":"fortran-wrapper/#application","title":"Application","text":""},{"location":"fortran-wrapper/#trac_fortranf90","title":"trac_fortran.f90","text":"<p>This program calculates trajectories based on MPTRAC's module_advect function. It is the Fortran counterpart to trac.c. The program is called with at least four (4) arguments:</p> <pre><code># calling trac_fortran\n$ ./trac_fortran  &lt;dirlist&gt; &lt;ctl&gt; &lt;atm_in&gt; &lt;metbase&gt;\n</code></pre> <p>The required arguments are:</p> <ul> <li> <p><code>dirlist</code>: A file containing directories to be processed. Each   directory has to have an own control parameter file and a starting   point file.</p> </li> <li> <p><code>ctl</code>: In the control parameter file the configuration parameters can   be set.</p> </li> <li> <p><code>atm_in</code>: The starting point file contains a list of starting points   for the trajectory calculation.</p> </li> <li> <p><code>metbase</code>: Here, the path to the meteorological data files and their   basename shall be given.</p> </li> </ul> <p>Example from the repository:</p> <pre><code># minimal required input to run trac_fortran\n$ ./trac_fortran data/dirlist trac.ctl atm_split.tab meteo/ei\n</code></pre> <p>In addition it is possible to append control parameters, giving the flag name first, followed by the parameter, all separated by a space. Example:</p> <pre><code>#\n$ ./trac_fortran data/dirlist trac.ctl atm_split.tab meteo/ei ATM_BASENAME atm_diff GRID_BASENAME grid_diff\n</code></pre>"},{"location":"fortran-wrapper/#interface","title":"Interface","text":""},{"location":"fortran-wrapper/#mptrac_fortranf90","title":"mptrac_fortran.f90","text":"<p>To ensure the interoperability between Fortran and C an interface is needed. This interface includes some general dimension variables, the structures <code>atm_t</code>, <code>clim_photo_t</code>, <code>clim_t</code>, <code>clim_ts_t</code>, <code>clim_zm_t</code>, <code>clt_t</code>, <code>met_t</code> and the functions <code>mptrac_get_met</code>, <code>mptrac_module_advect</code>, <code>mptrac_module_timesteps</code>, <code>mptrac_read_atm</code>, <code>mptrac_read_clim</code>, <code>mptrac_read_ctl</code>, <code>mptrac_read_met</code>, <code>mptrac_write_output</code>. The functions have always the prefix <code>mptrac</code> to indicate that they are only an interface calling the original MPTRAC function.</p>"},{"location":"fortran-wrapper/#checking-order-and-array-sizes","title":"Checking order and array sizes","text":"<p>It is crucial that the order and array sizes in the Fortran interface match those in the original C structure. The structures in MPTRAC consist of extensive variable lists (up to O100 for the control parameter list) and data types that may also depend on self-defined structures (struct of struct). A shell script <code>find_vars.sh</code> (in <code>tests/wrapper_test/</code>) can be used to check differences in the structures and variable dimensions. This script is automatically executed when the wrapper test is performed.</p>"},{"location":"fortran-wrapper/#example","title":"Example","text":"<p>An example of using the Fortran wrapper for trajectory calculations can be found in <code>tests/wrapper_test/run.sh</code>.</p> <p>This file executes the trajectory calculation first with the original C code <code>trac.c</code>. The output is stored in the directory <code>data.ref/</code>. Afterwards, the Fortran code <code>trac_fortran.f90</code> is called. This output is stored in the directory <code>data/</code>. Both directories are compared to make sure that the Fortran version produces the same results as the C version.</p>"},{"location":"high-level-interface/","title":"High-level interface","text":""},{"location":"high-level-interface/#overview","title":"Overview","text":"<p>The MPTRAC Lagrangian transport model provides a high-level interface for simulating atmospheric transport processes, which can be applied easily from other models.</p> <p>This high-level interface, implemented through the <code>mptrac_*</code> functions in <code>mptrac.c</code> and <code>mptrac.h</code>, facilitates memory management, initialization, data input/output, and simulation execution.</p> <p>This document describes the core functions of the interface and demonstrates their usage with an example workflow.</p>"},{"location":"high-level-interface/#function-categories","title":"Function categories","text":""},{"location":"high-level-interface/#1-memory-management","title":"1. Memory Management","text":"<ul> <li> <p><code>void mptrac_alloc(...)</code>: Allocates memory for control, cache, climatology, meteorology, and atmospheric data structures on the CPU and GPU.</p> </li> <li> <p><code>void mptrac_free(...)</code>: Frees memory allocated for these structures.</p> </li> </ul>"},{"location":"high-level-interface/#2-initialization-and-memory-updates","title":"2. Initialization and memory updates","text":"<ul> <li> <p><code>void mptrac_init(...)</code>: Initializes the MPTRAC model with control, cache, climatology, and atmospheric data. It adjusts the time range of the simulation and initializes the random number generator.</p> </li> <li> <p><code>void mptrac_update_device(...)</code>: Updates device memory with the latest data from CPU memory.</p> </li> <li> <p><code>void mptrac_update_host(...)</code>: Updates host memory from GPU memory.</p> </li> </ul>"},{"location":"high-level-interface/#3-data-input","title":"3. Data input","text":"<ul> <li> <p><code>void mptrac_read_ctl(...)</code>: Reads control parameters from a file or the command line.</p> </li> <li> <p><code>void mptrac_read_clim(...)</code>: Reads various climatology data from data files.</p> </li> <li> <p><code>int mptrac_read_met(...)</code>: Reads meteorological data from a file.</p> </li> <li> <p><code>int mptrac_read_atm(...)</code>: Reads air parcel data from a file.</p> </li> </ul>"},{"location":"high-level-interface/#4-data-output","title":"4. Data output","text":"<ul> <li> <p><code>void mptrac_write_output(...)</code>: Writes simulation results in various output types.</p> </li> <li> <p><code>void mptrac_write_met(...)</code>: Writes meteorological data to a file.</p> </li> <li> <p><code>void mptrac_write_atm(...)</code>: Writes air parcel data to a file.</p> </li> </ul>"},{"location":"high-level-interface/#5-simulation-execution","title":"5. Simulation execution","text":"<ul> <li><code>void mptrac_run_timestep(...)</code>: Executes a single timestep of the Lagrangian transport model. Simulates various processes such as advection, diffusion, convection, chemistry, etc.</li> </ul>"},{"location":"high-level-interface/#6-meteorological-data-handling","title":"6. Meteorological data handling","text":"<ul> <li><code>void mptrac_get_met(...)</code>: Retrieves meteorological data for a specific time.</li> </ul>"},{"location":"high-level-interface/#example-workflow","title":"Example workflow","text":"<p>Below is an example of how to use the high-level MPTRAC interface in a typical simulation. Please see <code>trac.c</code> for the full code.</p>"},{"location":"high-level-interface/#1-allocate-memory","title":"1. Allocate memory","text":"<pre><code>mptrac_alloc(&amp;ctl, &amp;cache, &amp;clim, &amp;met0, &amp;met1, &amp;atm);\n</code></pre>"},{"location":"high-level-interface/#2-initialize-the-model","title":"2. Initialize the model","text":"<pre><code>mptrac_read_ctl(filename, argc, argv, ctl);\nmptrac_read_clim(ctl, clim);\nmptrac_read_atm(filename, ctl, atm);\nmptrac_init(ctl, cache, clim, atm, ntask);\n</code></pre>"},{"location":"high-level-interface/#3-run-the-simulation","title":"3. Run the simulation","text":"<p>Within the time loop of the model, repeatedly call:</p> <pre><code>mptrac_get_met(ctl, clim, t, &amp;met0, &amp;met1);\nmptrac_run_timestep(ctl, cache, clim, &amp;met0, &amp;met1, atm, t);\nmptrac_write_output(dirname, ctl, met0, met1, atm, t);\n</code></pre>"},{"location":"high-level-interface/#4-free-memory","title":"4. Free memory","text":"<pre><code>mptrac_free(ctl, cache, clim, met0, met1, atm);\n</code></pre>"},{"location":"high-level-interface/#notes","title":"Notes","text":"<ul> <li> <p>Proper error handling is essential when reading input data or   allocating memory.</p> </li> <li> <p>The example workflow shown here handles GPU offloading and data   transfers between CPU and GPU memory. In other application, ensure   proper synchronization between host and device memory when using   GPUs.</p> </li> </ul>"},{"location":"high-level-interface/#references","title":"References","text":"<ul> <li> <p><code>mptrac.h</code>: Header file with function declarations.</p> </li> <li> <p><code>trac.c</code>: Example implementation of the MPTRAC interface.</p> </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>This guide covers the installation of MPTRAC on a Linux system. The process involves several steps: meeting prerequisites, downloading the source code, building the required libraries, compiling the source code, and verifying the installation.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>To build and run MPTRAC, you will need some basic tools and libraries, including Git, GNU Make, GCC, GSL, HDF5, and netCDF.</p> <p>For additional features such as HPC and GPU support, optional dependencies like OpenMPI and the NVIDIA HPC SDK are required.</p> <p>Some of the required dependencies are included with the MPTRAC repository. See the next section for more details.</p> <p>For a complete list of dependencies, including specific versions and installation instructions, refer to the dependencies file.</p>"},{"location":"installation/#downloading-the-source-code","title":"Downloading the source code","text":"<p>Get the latest or a previous version from the MPTRAC releases page. After downloading, extract the release file:</p> <pre><code>unzip mptrac-x.y.zip\n</code></pre> <p>Alternatively, to get the latest development version, clone the GitHub repository:</p> <pre><code>git clone https://github.com/slcs-jsc/mptrac.git\n</code></pre> <p>To update an existing installation, navigate to the directory and pull the latest changes:</p> <pre><code>git pull https://github.com/slcs-jsc/mptrac.git\n</code></pre>"},{"location":"installation/#building-the-libraries","title":"Building the libraries","text":"<p>MPTRAC includes several libraries that can be compiled and installed using a build script:</p> <pre><code>cd [mptrac_directory]/libs\n./build.sh -a\n</code></pre> <p>The build process of the libraries can take considerable time. If your system already has compatible versions of the libraries, consider using those instead.</p>"},{"location":"installation/#configure-the-makefile","title":"Configure the Makefile","text":"<p>Navigate to the source directory and adjust the <code>Makefile</code> as needed:</p> <pre><code>cd [mptrac_directory]/src\nemacs Makefile\n</code></pre> <p>Pay special attention to the following settings:</p> <ul> <li> <p>Edit the <code>LIBDIR</code> and <code>INCDIR</code> paths to point to the directories   where the GSL, netCDF, and other required libraries are located on   your system.</p> </li> <li> <p>By default, the MPTRAC binaries are linked dynamically. Ensure that   the <code>LD_LIBRARY_PATH</code> is properly configured to include the paths to   the shared libraries. If you prefer static linking, you can enable   it by setting the <code>STATIC</code> flag, which allows you to copy and use   the binaries on other machines. However, in some cases, either   static or dynamic linking may not be feasible or could cause   specific issues.</p> </li> <li> <p>To enable MPI parallelization in MPTRAC, you must set the <code>MPI</code>   flag. Additionally, an MPI library, such as OpenMPI, must be   installed on your system. To utilize OpenACC parallelization, enable   the <code>GPU</code> flag, and ensure the NVIDIA HPC SDK is installed to   compile the GPU code. OpenMP parallelization is always enabled.</p> </li> <li> <p>Some options in the Makefile are labeled as experimental. These   features are still under development and may not be fully functional   or tested. Use them at your own risk.</p> </li> </ul>"},{"location":"installation/#compile-and-test-the-installation","title":"Compile and test the installation","text":"<p>Once the Makefile is configured, compile the code using:</p> <pre><code>make [-j]\n</code></pre> <p>To verify the installation, run the test suite:</p> <pre><code>make check\n</code></pre> <p>These tests cover a wide range of MPTRAC functionalities. Make sure all tests pass successfully before using the model in other applications. If any test fails, check the log messages for further details.</p>"},{"location":"links/","title":"Links","text":"<p>These links provide further information for users and developers of MPTRAC:</p> <ul> <li> <p>README file</p> </li> <li> <p>User manual</p> </li> <li> <p>Doxygen manual</p> </li> <li> <p>AI documentation</p> </li> <li> <p>Reference paper</p> </li> <li> <p>Other references</p> </li> <li> <p>Citation file</p> </li> <li> <p>Code of conduct</p> </li> <li> <p>Contributing guidelines</p> </li> <li> <p>Software dependencies</p> </li> <li> <p>License</p> </li> </ul> <p>Links to external resources:</p> <ul> <li> <p>MPTRAC Web Runner</p> </li> <li> <p>Helmholtz Research Software Directory</p> </li> <li> <p>Rocket.Chat channel (internal)</p> </li> <li> <p>User and developer meeting (internal)</p> </li> <li> <p>MPTRAC Data Repository</p> </li> <li> <p>Reanalysis Tropopause Data Repository</p> </li> <li> <p>Nightly Builds</p> </li> <li> <p>ESM Buildbot (internal)</p> </li> <li> <p>exacb integration (internal)</p> </li> </ul>"},{"location":"meteorological-input-data/","title":"Meteorological input data","text":""},{"location":"meteorological-input-data/#introduction","title":"Introduction","text":"<p>The MPTRAC model needs meteorological input data (winds, temperature, ...) to perform the trajectory calculations and for other tasks.</p> <p>The meteo data should be provided as netCDF files on a regular grid  (pressure, longitude, latitude). Each time step of the reanalysis  data should be provided as a separate netCDF file. The time step of  the corresponding meteo data file is inferred from the filename  following this naming convention:</p> <pre><code>     &lt;basename&gt;_&lt;YYYY&gt;_&lt;MM&gt;_&lt;DD&gt;_&lt;HH&gt;.nc\n</code></pre> <p>At a minimum, MPTRAC needs temperature (netCDF variable name: <code>T</code>), zonal wind (<code>U</code>), and meridional wind (<code>V</code>). Additionally, many applications need the vertical velocity (<code>W</code>), specific humidity (<code>Q</code>) or relative humidity (<code>RH</code>), ozone (<code>O3</code>), cloud liquid/rain water content (<code>CLWC</code>/<code>CRWC</code>), cloud ice/snow water content (<code>CIWC</code>/<code>CSWC</code>), and cloud cover (<code>CC</code>).</p> <p>It is also necessary to provide the surface pressure (<code>LNSP</code>, <code>PS</code>, or <code>SP</code>) and the surface geopotential height (<code>Z</code> or <code>ZM</code>). Optionally, the surface temperature (<code>T2M</code>), the surface wind components (<code>U10M</code>, <code>V10M</code>), the land-sea mask (<code>LSM</code>), and sea surface temperature (<code>SSTK</code>) are read in.</p> <p>It is possible to provide meteo data on model levels rather than pressure levels. In this case, pressure on model levels (<code>PL</code>) is required as an additional 3-D input variable in order to perform a vertical interpolation from model levels to pressure levels.</p> <p>See the <code>tests/data/</code> directory in the MPTRAC repository for examples of meteo data netCDF files used for MPTRAC.</p>"},{"location":"meteorological-input-data/#the-ecmwf-reanalyses","title":"The ECMWF reanalyses","text":""},{"location":"meteorological-input-data/#overview","title":"Overview","text":"<p>As an example, we discuss the use of ERA5 reanalysis data provided by the European Centre for Medium-Range Weather Forecasts (ECMWF) to run the MPTRAC model.</p> <p>ERA5 provides hourly estimates of a large number of atmospheric, land and oceanic climate variables from 1950 to present. The data cover the Earth on a 30 km grid (T639 triangular truncation) and resolve the atmosphere using 137 levels from the surface up to a height of about 80 km. ERA5 includes information about uncertainties for all variables at reduced spatial and temporal resolutions.</p>"},{"location":"meteorological-input-data/#download-of-ecmwf-data","title":"Download of ECMWF data","text":"<p>The first step is to download the ERA5 data from the Copernicus Climate Change Service (C3S) Climate Date Store. It is recommended to download the data in grib file format at 0.3\u00b0x0.3\u00b0 horizontal resolution, on all 137 model levels, and at hourly time intervals.</p>"},{"location":"meteorological-input-data/#interpolation-to-pressure-levels","title":"Interpolation to pressure levels","text":"<p>The second step is to interpolate the ERA5 data from model levels to pressure levels. Here, a set of target pressure levels needs to be selected. It is recommended to use a set of 137 pressure levels that matches the vertical sampling of the IFS model level data as defined by a fixed surface pressure of 1013.25 hPa and ECMWF's a and b level coefficients.</p> <p>Potentially, the vertical sampling of the target pressure levels in the lower troposphere and the number of levels in the mesosphere can be reduced to reduce the amount of data.  However, it is highly recommended to add additional target pressure levels in the range of 1013.25 to about 1045 hPa to avoid extrapolation errors in case the actual surface pressure is larger than the standard pressure of 1013.25 hPa.</p> <p>The CDO tools can be used to perform the vertical interpolation from model levels to pressure levels and to convert from grib to netCDF file format. For example:</p> <pre><code>    # merge surface and model level grib files...\n    cdo -P 8 merge 2020010100_sf.grb 2020010100_ml.grb merge.grib\n\n    # interpolate to pressure levels and create netCDF file...\n    cdo -P 8 -a -f nc -t ecmwf ml2pl,104445,103725,103006,102286,101567,100847,100128,99408.1,98688.6,97969,97249.5,96529.9,95810.4,95090.8,94314,93476.7,92575.7,91608.1,90571.2,89462.2,88279.1,87020,85683.8,84269.6,82777.6,81208.5,79564,77846.6,76060,74208.6,72297.9,70334.7,68326.2,66280.8,64207.6,62116.2,60016.7,57919.3,55834.3,53772,51742,49758.4,47831,45963.2,44153.9,42401.9,40705.8,39064.5,37476.7,35941.1,34456.6,33022,31636.1,30297.6,29005.5,27758.5,26555.6,25395.5,24277.2,23199.5,22161.5,21161.9,20199.7,19273.9,18383.4,17527.3,16704.5,15914,15154.9,14426.2,13727,13056.4,12413.4,11797.1,11206.8,10641.5,10100.5,9582.8,9087.74,8614.5,8161.82,7728.1,7311.87,6911.87,6526.95,6156.07,5798.34,5452.99,5119.9,4799.15,4490.82,4194.93,3911.49,3640.47,3381.74,3135.12,2900.39,2677.35,2465.77,2265.43,2076.1,1897.52,1729.45,1571.62,1423.77,1285.61,1156.85,1037.2,926.34,823.97,729.74,643.34,564.41,492.62,427.59,368.98,316.42,269.54,227.97,191.34,159.28,131.43,107.42,86.9,69.52,54.96,42.88,32.99,24.99,18.61,13.61,9.75,6.83,4.67,3.1,2,1 -selname,lnsp,z,t,u,v,w,q,o3 merge.grib ea5_2020_01_01_00.nc\n</code></pre>"},{"location":"meteorological-input-data/#other-meteorological-data-sets","title":"Other meteorological data sets","text":"<p>The MPTRAC model has also been used with other meteorological data sets.</p> <p>The Modern-Era Retrospective analysis for Research and Applications, Version 2 (MERRA-2) provides data beginning in 1980. It was introduced to replace the original MERRA dataset because of the advances made in the assimilation system that enable the assimilation of modern hyperspectral radiance and microwave observations, along with GPS-Radio Occultation datasets. It also uses NASA's ozone profile observations that began in late 2004. Additional advances in both the GEOS model and the GSI assimilation system are included in MERRA-2. The spatial resolution remains about the same (about 50 km in the latitudinal direction) as in MERRA.</p> <p>The NCEP/NCAR Reanalysis 1 project is using a state-of-the-art analysis/forecast system to perform data assimilation using past data from 1948 to the present. A large subset of this data is available from PSL in its original 4 times daily format and as daily averages. However, the data from 1948-1957 is a little different, in the regular (non-Gaussian) gridded data. That data was done at 8 times daily in the model because the inputs available in that era were available at 3Z, 9Z, 15Z, and 21Z, whereas the 4x daily data has been available at 0Z, 6Z, 12Z, and 18Z. These latter times were forecasted and the combined result for this early era is 8x daily. The local ingestion process took only the 0Z, 6Z, 12Z, and 18Z forecasted values, and thus only those were used to make the daily time series and monthly means here.</p> <p>The Global Forecast System (GFS) is a weather forecast model produced by the National Centers for Environmental Prediction (NCEP). Dozens of atmospheric and land-soil variables are available through this dataset, from temperatures, winds, and precipitation to soil moisture and atmospheric ozone concentration. The entire globe is covered by the GFS at a base horizontal resolution of 18 miles (28 kilometers) between grid points, which is used by the operational forecasters who predict weather out to 16 days in the future. Horizontal resolution drops to 44 miles (70 kilometers) between grid points for forecasts between one week and two weeks.</p>"},{"location":"meteorological-input-data/#scripts-to-assist-data-download-and-preparation","title":"Scripts to assist data download and preparation","text":"<p>To assist users in downloading and preparing meteorological input data, MPTRAC provides example scripts in the <code>projects/meteo/</code> directory of the repository. These scripts cover the download and basic processing for ERA5, GFS, NCEP/NCAR Reanalysis 1, and MERRA-2 datasets.</p> <p>Please note that access to the respective data servers of the meteorological centers is required to use these scripts, and additional tools such as CDO are necessary for data conversion.</p> <p>While downloading and converting meteorological data files for use with MPTRAC is often the most challenging step for new users, these scripts are intended to simplify the process and serve as a helpful starting point.</p>"},{"location":"meteorological-input-data/#meteocloud-data-archive-in-julich","title":"MeteoCloud data archive in J\u00fclich","text":"<p>For registered users and collaboration partners at the J\u00fclich Supercomputing Centre, Germany, a number of meteorological data sets are readily available for MPTRAC in netCDF file format. The data sets are stored in the MeteoCloud data archive in J\u00fclich. Please contact us in order to inquire about getting access to the data.</p>"},{"location":"meteorological-input-data/#interoperability-with-clams-data","title":"Interoperability with CLaMS data","text":"<p>MPTRAC can read meteorological data that follows the data format guidelines for the CLaMS Lagrangian transport model. See the page on diabatic transport for further details.</p>"},{"location":"model-output-data/","title":"Model output data","text":"<p>MPTRAC currently supports eight different types of model output: particle output, grid output, CSI output, ensemble output, profile output, sample output, station output, and VTK output. By default, these output functions generate data in ASCII table format, which is human-readable and compatible with various data analysis and visualization tools. This format is ideal for quick inspection and post-processing, making it accessible for a wide range of users.</p> <p>However, for large-scale simulations or when handling extensive datasets, the ASCII format may become inefficient. To address this, MPTRAC offers the option to perform file I/O in more efficient formats such as binary or netCDF. These formats are particularly useful for managing large volumes of data, and they enable smoother integration with other tools and models, such as the CLaMS model for atmospheric studies.</p> <p>Additionally, MPTRAC provides the capability to pipe output data directly to visualization tools, such as the graphing utility Gnuplot, for real-time analysis and visualization. This flexibility allows users to tailor the output format to the needs of their simulation and analysis, improving both performance and usability.</p>"},{"location":"model-output-data/#particle-data","title":"Particle data","text":"<p>The most comprehensive output of MPTRAC is the particle data output. Particle data output files can be generated at user-defined time intervals, which need to be integer multiples of the model time step. The particle data output files are the most comprehensive type of output because they contain the time, location, and the values of all user-defined quantities of each individual air parcel.</p> <p>The air parcel output is configured using the <code>ATM_*</code> control parameters. The air parcel output file is set with the parameters <code>ATM_TYPE</code> and <code>ATM_TYPE_OUT</code>, where <code>ATM_TYPE</code> defines the file format for reading and <code>ATM_TYPE_OUT</code> defines the writing file format. However, if <code>ATM_TYPE_OUT</code> is not explicitly set in the control file, <code>ATM_TYPE</code> sets the file format for reading and writing.</p> ATM_TYPE output format 0 ASCII (default) 1 binary 2 netcdf 3 netcdf (CLaMS: trajectory and position file) 4 netcdf (CLaMS: position file)"},{"location":"model-output-data/#gridded-data","title":"Gridded data","text":"<p>To manage the potentially large size of particle output \u2014 especially when simulating many air parcels \u2014 MPTRAC supports gridded output as an efficient alternative for analysis. This output is generated by integrating the mass of all particles within a regular grid defined by longitude \u00d7 latitude \u00d7 log-pressure height.</p> <p>From the total mass in each grid cell and the corresponding air density, the column density and volume mixing ratio of the tracer are computed. If each particle is already assigned a volume mixing ratio, the system instead calculates and reports the mean volume mixing ratio per grid cell.</p> <p>For more targeted analyses, users can limit output to a single vertical layer to obtain total column values, or to a specific longitude band to compute zonal means. The grid output is configured using the <code>GRID_*</code> control parameters.  Gridded data can be written in either ASCII or netCDF format, depending on the setting of the <code>GRID_TYPE</code> parameter.</p> GRID_TYPE output format 0 ASCII (default) 1 netcdf"},{"location":"model-output-data/#csi-data","title":"CSI data","text":"<p>Another type of output that we used in several studies (Hoffmann et al., 2016; Heng et al., 2016) is the critical success index (CSI) output. This output is produced by analyzing model and observational data on a regular grid. The analysis is based on a 2\u00d72 contingency table of model predictions and observations. Here, predictions and observations are counted as yes, if the model column density or the observed variable exceed user-defined thresholds. Otherwise, they would be counted as no. Next to the CSI, the counts allow us to calculate the probability of detection (POD) and the false alarm rate (FAR), which are additional skill scores that are often considered in model verification. More recently, the CSI output was extended to also include the equitable threat score (ETS), the linear and rank-order correlation coefficients, the bias, the root mean square (RMS) difference, and the mean absolute error. A more detailed discussion of the skill scores is provided by Wilks (2011). The CSI output is configured using the <code>CSI_*</code> control parameters.</p>"},{"location":"model-output-data/#ensemble-data","title":"Ensemble data","text":"<p>Another option to condense comprehensive particle data is provided by means of the ensemble output. This type of output requires a user-defined specific ensemble index value to be assigned to each air parcel. Instead of the individual air parcel data, the ensemble output will contain the mean positions as well as the means and standard deviations of the quantities selected for output for each set of air parcels having the same ensemble index. The ensemble output if of interest, if tracer dispersion from multiple point sources needs to be quantified by means of a single model run, for instance. The ensemble output is configured using the <code>ENS_*</code> control parameters.</p>"},{"location":"model-output-data/#profile-data","title":"Profile data","text":"<p>The profile output of MPTRAC is similar to the grid output as it creates vertical profiles from the model data on a regular longitude\u2009\u00d7\u2009latitude horizontal grid. However, the vertical profiles contain not only volume mixing ratios of the species of interest but also profiles of pressure, temperature, water vapor, and ozone as inferred from the meteorological input data. This output is compiled with the intention to be used as input for a radiative transfer model, in order to simulate satellite observations for the given model output. In combination with real satellite observations, this output can be used for model validation but also as a basis for radiance data assimilation. The profile output is configured using the <code>PROF_*</code> control parameters.</p>"},{"location":"model-output-data/#sample-data","title":"Sample data","text":"<p>The sample output of MPTRAC was implemented most recently. It allows the user to extract model information on a list of given locations and times, by calculating the column density and volume mixing ratio of all parcels located within a user-specified horizontal search radius and vertical height range. For large numbers of sampling locations and air parcels, this type of output can become rather time-consuming. It requires an efficient implementation and parallelization because it needs to be tested at each time step of the model whether an air parcel is located within a sampling volume or not. The numerical effort scales linearly with both the number of air parcels and the number of sampling volumes. The sample output was first applied in the study of Cai et al. (2021) to sample MPTRAC data directly on TROPOspheric Monitoring Instrument (TROPOMI) satellite observations. The sample output is configured using the <code>SAMPLE_*</code> control parameters.</p>"},{"location":"model-output-data/#station-data","title":"Station data","text":"<p>Finally, the station output is collecting the data of air parcels that are located within a search radius around a given location (latitude, longitude). The vertical position is not considered here; i.e., the information of all air parcels within the vertical column over the station is collected. In order to avoid double counting of air parcels over multiple time steps, the quantity STAT has been introduced that keeps track on whether an air parcel has already been accounted for in the station output or not. We used this type of output in studies estimating volcanic emissions from satellite observations using the backward-trajectory method (Hoffmann et al., 2016; Wu et al., 2017, 2018). The station output is configured using the <code>STAT_*</code> control parameters.</p>"},{"location":"model-output-data/#vtk-data","title":"VTK data","text":"<p>MPTRAC also supports outputting air parcel data in VTK (Visualization Toolkit) format, which is commonly used for visualizing and analyzing simulation results in 3D. The VTK output provides detailed information about the positions and properties of air parcels at each user-defined time step. The VTK output can be enabled by specifying the appropriate parameters in the control file. This output includes the time, location (longitude, latitude, and altitude), and other properties of each air parcel, allowing for advanced visualization and post-processing. The frequency of output is controlled by user-defined time intervals, which must be integer multiples of the model's time step. The VTK output is configured using the <code>VTK_*</code> control parameters. Please see <code>projects/paraview/README.md</code> for further instructions and examples on how to create VTK output.</p>"},{"location":"model-physics/","title":"Model physics","text":""},{"location":"model-physics/#advection","title":"Advection","text":"<p>The advection of an air parcel, i.\\,e., the position \\(\\vec{x}(t)\\) at time \\(t\\) for a given wind and velocity field \\(\\vec{v}(\\vec{x}, t)\\), is given by the trajectory equation,</p> \\[ \\begin{align}   \\frac{d\\vec{x}}{dt}=\\vec{v}(\\vec{x}, t). \\end{align} \\] <p>Here, the position \\(\\vec{x}\\) is provided in a meteorological coordinate system, \\(\\vec{x}=(\\lambda,\\phi,p)\\), with longitude \\(\\lambda\\), latitude \\(\\phi\\), and a vertical coordinate (pressure \\(p\\) or zeta \\(\\zeta\\)). The velocity vector \\(\\vec{v}=(u,v,\\omega)\\) is composed of the zonal wind component \\(u\\), the meridional wind component \\(v\\), and the vertical velocity (\\(\\omega\\) or \\(\\dot{\\zeta}\\)), respectively.</p>"},{"location":"model-physics/#integration-method","title":"Integration Method","text":"<p>Based on its accuracy and computational efficiency for trajectory calculations (R\u00f6\u00dfler et al., 2018), per default we apply the explicit midpoint method to solve the trajectory equation,</p> \\[ \\begin{align}   \\vec{x}(t+\\Delta t) = \\vec{x}(t) + \\vec{v}(\\vec{x}(t) + \\frac{\\Delta t}{2}\\vec{v}\\left[\\vec{x}(t), t\\right], t+\\frac{\\Delta t}{2})  \\Delta t. \\end{align} \\] <p>As an alternative, the classical 4th-order Runge-Kutta method can be employed for the simulation, which has higher accuracy at higher computational costs. The method is defined by the equations:</p> \\[ \\begin{align} \\vec{x}(t+\\Delta t) = \\vec{x}(t) + \\frac{1}{6}\\left(k_1 + 2k_2 + 2k_3 + k_4 \\right)\\Delta t\\\\ \\end{align} \\] \\[ \\begin{align}  \\vec{k_1} = \\vec{v}(t, \\vec{x}(t))\\\\  \\vec{k_2} = \\vec{v}\\left(t + \\frac{\\Delta t}{2}, \\vec{x}(t) + \\Delta t\\frac{k_1}{2}\\right)\\\\  \\vec{k_3} = \\vec{v}\\left(t + \\frac{\\Delta t}{2}, \\vec{x}(t) + \\Delta t\\frac{k_2}{2}\\right)\\\\  \\vec{k_4} = \\vec{v}\\left(t + \\Delta t, \\vec{x}(t) + \\Delta t\\,k_3\\right) \\end{align} \\] <p>Finally, MPTRAC can use the Euler method as well. The Euler method has low accuracy but is the fastest option available.</p> <p>The integration method is selected with the parameter <code>ADVECT</code>.</p> ADVECT Integration Method 1 explicit Euler 2 (default) mid-point 4 classical 4th order Runge-Kutta"},{"location":"model-physics/#vertical-coordinate-and-diabatickinematic-velocities","title":"Vertical coordinate and diabatic/kinematic velocities","text":"<p>Besides the pressure coordinate with the pressure tendency as vertical velocity, MPTRAC applies the hybrid vertical coordinate \\(\\zeta\\) with associated diabatic vertical velocity \\(\\dot\\zeta=\\frac{d\\zeta}{dt}\\) for trajectory calculations. The hybrid coordinate \\(\\zeta\\) is defined as shown in the equation below. Near the surface, the hybrid coordinate \\(\\zeta\\) follows the orography in the form of a sigma-like coordinate \\(\\sigma=\\frac{p}{p_s}\\), where \\(p_s\\) is the surface pressure. At higher altitudes, above \\(\\sigma_{r}=0.3\\), the zeta coordinate is smoothly transformed into the potential temperature \\(\\theta(p)\\) (see also Mahowald et al, 2004).</p> \\[ \\begin{equation}     \\zeta(p) = \\begin{cases}                 \\theta(p) &amp; \\text{if}\\,\\sigma &lt; \\sigma_r \\\\                 \\theta(p) \\sin{\\left(\\frac{1-\\sigma(p)}{1-\\sigma_r}\\right)} &amp; \\text{if}\\,\\sigma \\geq \\sigma_r                 \\end{cases} \\end{equation} \\] <p>While kinematic velocities are derived from the continuity equation diabatic velocities are obtained by radiative calculations. Diabatic velocities are well-suited for stratospheric transport processes, because of the isentropic nature of transport at this height. However, in the troposphere, where parameterisations of mixing in the boundary layer and for convection are needed, most modules rely on a formulation in pressure coordinates (see e.g. convection, turbulent diffusion below).  MPTRAC allows a coupled mode, where advection is performed in hybrid coordinates (\\(\\zeta\\)) but other modules can be employed in pressure coordinates.</p>"},{"location":"model-physics/#turbulent-diffusion","title":"Turbulent diffusion","text":"<p>Rather complex parameterizations of atmospheric diffusivity are available for the planetary boundary layer. Much less is known on the diffusivities in the free troposphere and in the stratosphere, being in the scope of the MPTRAC model. In our model, the effects of atmospheric diffusion are simulated by adding stochastic perturbations to the positions \\(\\vec{x}\\) of the air parcels at each time step \\(\\Delta t\\) of the model,</p> \\[ \\begin{align}   \\Delta x_i(t+\\Delta t) = x_i(t) + \\sqrt{2\\,D_i\\,\\Delta t}\\xi_i. \\end{align} \\] <p>This method requires a vector \\(\\vec{\\xi}=(\\xi_x, \\xi_y, \\xi_z)\\) of random variates to be drawn from the standard normal distribution for each air parcel at each time step. The vector of diffusivities \\(\\vec{d}=(D_x, D_x, D_z)\\) is composed of the horizontal diffusivity \\(D_x\\) and the vertical diffusivity \\(D_z\\). The model allows to specify \\(D_x\\) and \\(D_z\\) separately for the troposphere and stratosphere as control parameters. A smooth transition between tropospheric and stratospheric diffusivities is created within a \\(\\pm 1km\\) log-pressure altitude range around the tropopause. The tropopause's pressure level is determined by linear interpolation from a monthly mean zonal mean climatology derived from the NCEP/NCAR Reanalysis 1 project (Kalnay et al, 1996). Following choices made for the FLEXPART model (Stohl et al, 2005), default values of \\(D_x=50m^2s^{-1}\\) and \\(D_z=0\\) have been selected for the troposphere and \\(D_x=0\\) and \\(D_z=0.1m^2s^{-1}\\) have been selected for the stratosphere.</p> <p>Note that for simulations without diffusion, the diffusivity needs to be set to zero everywhere. To specify the diffusivity in the stratosphere and troposphere as desired the following parameters can be used:</p> Parameter Layer Direction Default TURB_DX_TROP Troposphere horizontal \\(50~\\rm{m^2~s^{-1}}\\) TURB_DX_STRAT Stratosphere horizontal \\(0~\\rm{m^2~s^{-1}}\\) TURB_DZ_TROP Troposphere vertical \\(0~\\rm{m^2~s^{-1}}\\) TURB_DZ_STRAT Stratosphere vertical \\(0.1~\\rm{m^2~s^{-1}}\\)"},{"location":"model-physics/#subgrid-scale-wind-fluctuations","title":"Subgrid-scale wind fluctuations","text":"<p>In addition to turbulent diffusion, the effects of unresolved subgrid-scale winds, also referred to as mesoscale wind perturbations, are considered. The starting point for this approach is the separation of the horizontal wind and vertical velocity vector \\(\\vec{v}\\) into the grid-scale mean \\(\\bar{\\vec{v}}\\) and the subgrid-scale perturbations \\(\\vec{v}'\\),</p> \\[ \\begin{equation}   \\vec{v}=\\bar{\\vec{v}} + \\vec{v}'. \\end{equation} \\] <p>It is further assumed that the mean wind \\(\\bar{\\vec{v}}\\) is given by the coarse-grid meteorological data, whereas the wind perturbations \\(\\vec{v}'\\) need to be modelled. The sub-grid scale wind perturbations are simulated by means of a Langevin equation,</p> \\[ \\begin{align}   &amp; v_i'(t+\\Delta t) = rv_i'(t) + \\sqrt{1-r^2} (f\\sigma_i)^2 \\xi_i, \\\\   &amp; r = 1-2\\frac{\\Delta t}{\\Delta t_{met}}. \\end{align} \\] <p>Mathematically, this represents a Markov chain or a random walk, which adds temporally correlated stochastic perturbations to the winds over time. The degree of correlation depends on the correlation coefficient \\(r\\), and therefore on the time step \\(\\Delta t\\) of the model and the time step \\(\\Delta t_{met}\\) of the meteorological data. The variance \\((f\\sigma_i)^2\\) of the random component added at each time step depends on the grid-scale variance \\(\\sigma_i^2\\) of the wind and velocity data and a scaling factor \\(f\\), which is used for downscaling to the subgrid scale. The scaling factor \\(f\\) needs to be specified as a control parameter of the model. The default value is \\(f=40\\)%, following a choice made for the FLEXPART model (Stohl et al., 2005). For each air parcel, the grid-scale variance \\(\\sigma_i^2\\) is calculated from the neighbouring eight grid boxes and two-time step of the meteorological data. To make computations more efficient, the grid-scale variance of each parcel is kept in cache. As before, \\(\\vec{\\xi}\\) is a vector of random variates to be drawn from the standard normal distribution.</p> <p>The scaling factor f is not directly set in MPTRAC. Instead the square \\(f^2\\) can be set for the vertical and horizontal dispersion of air parcels with the parameters <code>TURB_MESOX</code> and <code>TURB_MESOZ</code>. Accordingly their default value is 16%.</p>"},{"location":"model-physics/#convection","title":"Convection","text":"<p>The convection parameterization implemented in MPTRAC introduces the concept of the Extreme Convection Parametrization (ECP) to efficiently simulate convective effects within Lagrangian transport models. This method is based on the assumption that convective events create well-mixed columns of air, and it leverages convective available potential energy (CAPE), convective inhibition (CIN) and equilibrium level (EL) data from meteorological fields to capture this behavior.</p> <p>The fundamental idea underlying the ECP approach involves several key steps. First, the meteorological fields are used to interpolate gridded CAPE, CIN and EL values to the horizontal positions of individual air parcels within the Lagrangian model. Then, user-defined thresholds of \\(\\sf{CAPE_0}\\) and \\(\\sf{CIN_0}\\) are applied globally. If the interpolated CAPE value of an air parcel surpasses the \\(\\sf{CAPE_0}\\) threshold or the interpolated CIN value is below the \\(\\sf{CIN_0}\\) threshold and the parcel's position is below the EL, the model triggers a convective event.</p> <p>During a convective event, air parcels affected by the event are subject to random vertical redistribution within the atmospheric column, spanning from the Earth's surface to the equilibrium level. This vertical redistribution takes into account air density to ensure the creation of a well-mixed column of air. Importantly, this redistribution process adheres to mass conservation principles, maintaining both the number of air parcels and their collective mass constant.</p> <p>In subsequent time steps of the model, the trajectories of air parcels are continued from their new vertical positions, assigned during the convective mixing event. This dynamic approach enables the model to capture the transport implications of convective events, while also accounting for the vertical mixing effects they induce.</p> <p>The ECP method within MPTRAC is versatile and accommodates different simulation scenarios based on the chosen threshold \\(\\sf{CAPE_0}\\). By setting \\(\\sf{CAPE_0}\\) to zero, the model implements the \"extreme convection\" approach, where convection is simulated wherever CAPE exists below the EL. This represents an upper-limit scenario for the effects of unresolved convection in the meteorological fields. On the other hand, by turning off the ECP entirely, only explicitly resolved convective updrafts of the meteorological fields are considered, representing a lower-limit scenario. Intermediate states can be simulated by selecting specific values for threshold \\(\\sf{CAPE_0}\\). The parameter \\(\\sf{CIN_0}\\) can be used to prevent triggered convection in regions where a larger lower-level inversion layer is located, with high CAPE above it.</p> <p>The frequency of applying the ECP can be customized to the simulation's requirements. It can be implemented every model time step or at user-defined intervals that match typical convective timescales. This adaptability adds to the flexibility of the ECP method, making it suitable for a variety of simulation contexts.</p> <p>The convection parameterisation is set off per default, i.e. values are set to -999.</p> Parameter Explanation Default Value CONV_CAPE CAPE threshold -999 CONV_CIN CIN threshold -999 CONV_DT evaluation interval -999"},{"location":"model-physics/#sedimentation","title":"Sedimentation","text":"<p>In order to take into account the gravitational settling of particles, the sedimentation velocity \\(v_s\\) needs to be calculated. Using \\(v_s\\), the change of the vertical position of the particles over the model time step \\(\\Delta t\\) can be calculated. In MPTRAC, \\(v_s\\) is calculated for spherical particles following the method described by Jacobson (1999). In the first step, we calculate the density of dry air,</p> \\[ \\begin{equation}   \\rho=\\frac{p}{RT}, \\end{equation} \\] <p>using the atmospheric pressure \\(p\\), temperature \\(T\\), and the specific gas constant \\(R\\) of dry air. The dynamic viscosity of air,</p> \\[ \\begin{equation}   \\eta=1.832515 \\cdot 10^{-5} \\frac{\\rm{kg}}{\\rm{m}~\\rm{s}} \\left (\\frac{416.16~\\sf{K}}{T+120~\\rm{K}} \\right ) \\left (\\frac{T}{296.16~\\rm{K}} \\right )^{1.5},   \\end{equation} \\] <p>and the thermal velocity of an air molecule,</p> \\[ \\begin{equation}   v=\\sqrt{\\rho RT},  \\end{equation} \\] <p>are used to calculate the mean free path of an air molecule \\(\\lambda\\), as well as the Knudsen number \\(K_n\\) for air,</p> \\[ \\begin{equation}   \\lambda=\\frac{\\rho}{2\\eta v} \\quad \\text{and} \\quad K_n=\\frac{\\lambda}{r_p}, \\end{equation} \\] <p>where \\(r_p\\) refers to the particle radius. The Cunningham slipflow correction is calculated from</p> \\[ \\begin{equation}   G=1+K \\left [1.249+0.42 \\exp \\left ( \\frac{-0.87}{K} \\right ) \\right] \\end{equation} \\] <p>Finally, the sedimentation velocity is obtained by means of Stokes law and from the slip-flow correction,</p> \\[ \\begin{equation}  v_s=\\frac{2r_p^2g(\\rho_p-\\rho)}{9\\eta}G \\end{equation} \\] <p>with particle density \\(\\rho_p\\) and conventional standard gravitational acceleration g. Note that \\(r_p\\) and \\(\\rho_p\\) can be specified individually for each air parcel. A larger set of parcels can be used to represent a size distribution of aerosol or cloud particles.</p>"},{"location":"model-physics/#wet-deposition","title":"Wet deposition","text":"<p>Wet deposition causes the removal of trace gases and aerosol particles from the atmosphere within or below clouds by mixing with suspended water and following washout through rain, snow, or fog. Wet deposition in MPTRAC is calculated based on the following four steps:</p> <p>(1) it is determined whether an air parcel is located below a cloud top. The cloud-top pressure \\(p_{ct}\\) is determined from the meteorological data as the highest vertical level where cloud water or ice (i.e., CLWC, CRWC, CIWC, or CSWC) is existent.</p> <p>(2) the wet deposition parametrization determines an estimate of the subgrid-scale precipitation rate \\(I_s\\), which is needed to calculate the scavenging coefficient \\(\\Lambda\\). The precipitation rate \\(I_s\\) (in units of \\(\\rm{mm h^{-1}}\\)) is calculated from the total column cloud water \\(c_l\\) (in units of \\(\\rm{kg m^{-2}}\\)) by means of a correlation function reported by Pisso et al. (2019),</p> \\[ \\begin{equation}  I_s= (2c_l)^{1/0.36}, \\end{equation} \\] <p>(3) it is inferred whether the air parcel is located within or below the cloud because scavenging coefficients will be different under these conditions. The position of the air parcel within or below the cloud is determined by interpolating the cloud water content to the position of the air parcel and by testing whether the interpolated values are larger than zero.</p> <p>(4) the scavenging coefficient \\(\\Lambda\\) is calculated based on the precipitation rate \\(I_s\\),</p> \\[ \\begin{equation}  \\Lambda=HRT I_s \\Delta z_c^{-1}, \\end{equation} \\] <p>where H is Henry\u2019s law constant, R is the universal gas constant, and \\(\\Delta z_c\\) is the depth of the cloud layer, which is calculated from \\(p_{ct}\\) and \\(p_{cb}\\). Henry\u2019s law constant is obtained from</p> \\[ \\begin{equation}   H(T)=H^\\ominus \\exp \\left [\\frac{\\Lambda_{sol}H}{R} \\left (\\frac{1}{T}-\\frac{1}{T^\\ominus}  \\right ) \\right]  \\end{equation} \\] <p>The constants \\(H^\\ominus\\) and \\(\\Delta_{sol}H/R\\) with enthalpy of dissolution \\(\\Delta_{sol}H\\) at the reference temperature \\(T^\\ominus=298.15~K\\) need to be specified as control parameters. Values for a wide range of species are tabulated by Sander (2015). The values of selected species of interest are summarized in the following table are included as default parameters in MPTRAC.</p> Species \\(H^\\ominus\\) (at 298.15 K) \\(-\\frac{\\Delta_{sol}H}{R}\\) \\(\\sf{CF_2Cl_2}\\) 3.0 \\(\\cdot 10^{-5}\\) 3500 \\(\\sf{CFCl_3}\\) 1.1 \\(\\cdot 10^{-4}\\) 3300 \\(\\sf{CH_4}\\) 1.4 \\(\\cdot 10^{-5}\\) 1600 \\(\\sf{CO}\\) 9.7 \\(\\cdot 10^{-6}\\) 1300 \\(\\sf{CO_2}\\) 3.3 \\(\\cdot 10^{-4}\\) 2400 \\(\\sf{N_2O}\\) 2.4 \\(\\cdot 10^{-4}\\) 2600 \\(\\sf{NH_3}\\) 5.9 \\(\\cdot 10^{-1}\\) 4200 \\(\\sf{HNO_3}\\) 2.1 \\(\\cdot 10^3\\) 8700 \\(\\sf{NO}\\) 1.9 \\(\\cdot 10^{-5}\\) 1600 \\(\\sf{NO_2}\\) 1.2 \\(\\cdot 10^{-4}\\) 2400 \\(\\sf{O_3}\\) 1.0 \\(\\cdot 10^{-4}\\) 2800 \\(\\sf{SF_6}\\) 2.4 \\(\\cdot 10^{-6}\\) 3100 \\(\\sf{SO_2}\\) 1.3 \\(\\cdot 10^{-2}\\) 2900"},{"location":"model-physics/#dry-deposition","title":"Dry deposition","text":"<p>Dry deposition leads to a loss of mass of aerosol particles or trace gases by gravitational settling or chemical and physical interactions with the surface of the dry phase. In the parametrization implemented in MPTRAC, dry deposition is calculated for air parcels located in the lowermost \\(\\Delta_p=\\) 30 hPa layer above the surface. This corresponds to a layer width of \\(\\Delta z \\approx\\) 200 m at standard conditions.</p> <p>For aerosol particles, the deposition velocity \\(v_{dep}\\) will be calculated as described in Hoffmann et al. (2022) as a function of surface pressure \\(p\\) and temperature \\(T\\) as well as particle radius \\(r_p\\) and particle density \\(\\rho\\). For trace gases, the deposition velocity \\(v_{dep}\\) needs to be specified as a control parameter. Currently, this parameter is set to a constant value across the globe for each trace gas. For future applications with a stronger focus on the boundary layer, \\(v_{dep}\\) will need to vary geographically to account for dependence on the surface characteristics and atmospheric conditions.</p> <p>For both particles and gases, the loss of mass is calculated based on the deposition velocity \\(v_{dep}\\), the model time step \\(\\Delta t\\), and the surface layer width \\(\\Delta z\\) from</p> \\[ \\begin{equation}   m(t+\\Delta t)=M(t) \\mathrm{exp} \\left ( -\\frac{\\Delta t v_{dep}}{\\Delta z} \\right ) \\end{equation} \\]"},{"location":"model-physics/#hydroxyl-chemistry","title":"Hydroxyl chemistry","text":"<p>The hydroxyl radical (OH) is an important oxidant in the atmosphere, causing the decomposition of many gas-phase species. The oxidation of different gas-phase species with OH can be classified into two main categories, bimolecular reactions (e.g., reactions of \\(\\sf{CH_4}\\) or \\(\\sf{NH_3}\\)), and termolecular reactions (e.g., CO or \\(\\sf{SO_2}\\)).</p> <p>For bimolecular reactions, the rate constant is calculated from Arrhenius law,</p> \\[ \\begin{equation}   k(T)=A \\times \\mathrm{exp} \\left ( -\\frac{E}{RT} \\right ) \\end{equation} \\] <p>with Avogadro constant \\(N_A\\). For the calculation of the second-order rate constant k see Eq. 25 in Hoffmann et al. (2022).</p> <p>For the calculation of k the low- and high-pressure limits of the reaction rate constant are given by</p> \\[ \\begin{equation}   k_0=k_0^{298} \\left ( \\frac{T}{298} \\right )^{-n}, \\quad   k_\\infty=k_\\infty^{298} \\left ( \\frac{T}{298}\\right )^{-m} . \\end{equation} \\] <p>The constants \\(k_0^{298}\\) and \\(k_\\infty^{298}\\) at the reference temperature of 298 K and the exponents n and m need to be specified as control parameters. The exponents can be set to zero in order to neglect the temperature dependence of the low- or high pressure limits of \\(k_0\\) and \\(k_\\infty\\). The termolecular reaction rate coefficients implemented directly into MPTRAC are listed in the table.</p> Reaction A factor E/R \\(\\sf{CH}_4+\\sf{OH} \\to \\sf{CH}_3+\\rm{H_2O}\\) 2.45 \\(\\cdot 10^{-12}\\) 1775 \\(\\sf{NH}_3+\\sf{OH} \\to \\sf{H_2O}+\\rm{NH}_2\\) 1.7 \\(\\cdot 10^{-12}\\) 710 \\(\\sf{O}_3+\\sf{OH} \\to \\sf{HO}_2+\\rm{O}_2\\) 1.7 \\(\\cdot 10^{-12}\\) 940 <p>Where A is in \\(\\sf{cm^{-3}}\\sf{molec^{-1}} \\sf{s^{-1}}\\) and E/R in K.</p> <p>Based on the bimolecular reaction rate k=k(T) or the termolecular reaction rate k=k(T, [M]), the loss of mass of the gas-phase species over time is calculated from</p> \\[ \\begin{equation} m(t+\\Delta t)=m(t) \\mathrm{exp} (-k[OH] \\Delta t). \\end{equation} \\] <p>The hydroxyl radical concentrations [OH] are obtained by bilinear interpolation from the monthly mean zonal mean climatology of Pommrich et al. (2014). This approach is suitable for global simulations covering at least several days, as hydroxyl concentrations may vary significantly between day and nighttime as well as the local atmospheric composition.</p>"},{"location":"model-physics/#exponential-decay","title":"Exponential decay","text":"<p>A rather generic module was implemented in MPTRAC, to simulate the loss of mass of an air parcel over a model time step \\(\\Delta t\\) due to any kind of exponential decay process, e.g., chemical loss or radioactivity,</p> \\[ \\begin{equation} m(t+\\Delta t)=m(t)\\mathrm{exp} \\left ( -\\frac{\\Delta t}{t_e} \\right ). \\end{equation} \\] <p>The e-folding lifetime \\(t_e\\) of the species needs to be specified as a control parameter. As typical lifetimes may differ, we implemented an option to specify separate lifetimes for the troposphere and stratosphere. A smooth transition between the tropospheric and stratospheric lifetime is created within a 1 km log-pressure altitude range around the tropopause.</p>"},{"location":"model-physics/#boundary-conditions","title":"Boundary conditions","text":"<p>When an air parcels reach the upper and lower boundary layer two options are available. First, they can be reflected back or second, their position is set to the lowest or highest height level available in the meteorological data and hence will slide along the boundaries until updrafts or downdrafts transport them back into the wider model domain. Those two options can be selected with the parameter REFLECT, which is 1 if air parcels are supposed to be reflected and 0 if they are supposed to be set to the boundary heights. The default value is 0, hence no reflection.</p>"},{"location":"parallelization/","title":"Parallelization","text":""},{"location":"parallelization/#introduction","title":"Introduction","text":"<p>MPTRAC features an MPI-OpenMP-OpenACC hybrid parallelization for efficient use on supercomputers and GPUs. An application built with the hybrid model of parallel programming can run on a compute cluster using both OpenMP and MPI, such that OpenMP is used for parallelism within a (multi-core) node while MPI is used for parallelism between nodes. In combination with MPI, OpenACC can be used to conduct multi-GPU simulations.</p> <p>MPI (Message Passing Interface) is a communication protocol for programming parallel computers. Both point-to-point and collective communication are supported. MPI is a message-passing application programmer interface, together with protocol and semantic specifications for how its features must behave in any implementation. MPI's goals are high performance, scalability, and portability. MPI remains the dominant model used in high-performance computing today.</p> <p>The application programming interface OpenMP (Open Multi-Processing) supports multi-platform shared-memory multiprocessing programming in C, C++, and Fortran, on many platforms, instruction-set architectures and operating systems. It consists of a set of compiler directives, library routines, and environment variables that influence run-time behavior. OpenMP uses a portable, scalable model that gives programmers a simple and flexible interface for developing parallel applications for platforms ranging from the standard desktop computer to the supercomputer.</p> <p>OpenACC (for open accelerators) is a programming standard for parallel computing developed by Cray, CAPS, Nvidia and PGI. The standard is designed to simplify parallel programming of heterogeneous CPU/GPU systems. As in OpenMP, the programmer can annotate C, C++, and Fortran source code to identify the areas that should be accelerated using compiler directives and additional functions.</p>"},{"location":"parallelization/#parallelization-strategy-of-mptrac","title":"Parallelization strategy of MPTRAC","text":"<p>In MPTRAC, the OpenMP parallelization is always enabled to exploit the multi-core compute capabilities of modern computing systems. The OpenMP parallelization is used to distribute the trajectory calculations for the air parcels of a single simulation over the cores of a single compute node. The calculations share the same meteorological data, i.e., only a single copy of this potentially large data set needs to be kept in memory. As the trajectory calculations typically need most of the total runtime of the simulations but can be conducted independently of each other, this parallelization scales very effectively over a large range of compute cores. The OpenMP scalability of MPTRAC has been discussed in the study of R\u00f6\u00dfler et al. [2018].</p> <p>The MPI parallelization of MPTRAC can be used to distribute a set of independent simulations (i.e., an ensemble of simulations) over a range of compute nodes. The simulations will run independently of each other, with their own individual input data and control parameters. A list of directories providing the input data for the different simulations needs to be provided as a control parameter to the trac tool. The trac tool will distribute this list of simulations over the different compute nodes. On each compute node, the individual simulations will be parallelized with OpenMP to make use of the different compute cores of each node. Also, mixed MPI/OpenMP setups are possible. For example, on a single compute node consisting of 48 compute cores, 4 independent simulations can be conducted by means of MPI, where each simulation employs 12 compute cores of the node by means of OpenMP.</p> <p>If the compute nodes are equipped with GPUS, the MPTRAC can make use of these by means of the OpenACC parallelization. In particular, the compute-intensive parts of the trajectory calculations will be offloaded to the GPUs. As modern computing systems typically provide more than one GPU per compute node, the MPI parallelization of MPTRAC needs to be used to exploit all the GPUs of a node for the calculations. For example, for compute nodes equipped with 4 GPUs, at least 4 individual simulations need to be performed to make use of all GPUs. At the same time, the OpenMP parallelization should be used to make efficient use of the CPUs. If the compute nodes have 48 cores, then 12 cores per simulation should be employed by means of OpenMP.</p> <p>Various combinations of an MPI/OpenMP/OpenACC hybrid parallelization can be configured. The best parallelization setup will depend on the requirements for the individual simulations and the target computing system.</p>"},{"location":"parallelization/#supercomputers-in-julich","title":"Supercomputers in J\u00fclich","text":"<p>The JUWELS cluster module is composed of more than 2000 standard compute nodes. Each compute node consists of 48 compute cores and is equipped with 96 GByte of memory. Although there are 48 compute cores physically, a larger number of cores, e.g., 96 cores, can be used by means of the hyper-threading approach in the OpenMP parallelization. Hyper-threading can help to use the compute cores more effectively.</p> <p>The JUWELS booster module is composed of 936 compute nodes with 48 cores and 512 GByte per node. Each compute node is equipped with 4 NVIDIA A100 Tensor Core-GPUs, which can be used by means of the OpenACC parallelization.</p> <p>Examples of how to set up the job scripts for different types of MPI/OpenMP/OpenACC simulations can be found in JUWELS Quick Introduction.</p> <p>Alternatively, MPTRAC has also been used on the JURECA-DC system.</p>"},{"location":"parallelization/#further-reading","title":"Further Reading","text":"<ul> <li>MPI Forum</li> <li>OpenMP</li> <li>OpenACC</li> </ul>"},{"location":"profiling/","title":"Profiling","text":""},{"location":"profiling/#introduction","title":"Introduction","text":"<p>In software engineering, profiling is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls. Most commonly, profiling information serves to aid program optimization.</p> <p>Profiling is achieved by instrumenting either the program's source code or its binary executable with a tool called a profiler (or code profiler). Profilers may use a number of different techniques, such as event-based, statistical, instrumentation-based, and simulation methods.</p> <p>Profilers use a wide variety of techniques to collect data, including hardware interrupts, code instrumentation, instruction set simulation, operating system hooks, and performance counters. Profilers are commonly used in the performance engineering process.</p>"},{"location":"profiling/#timers-in-mptrac","title":"Timers in MPTRAC","text":"<p>A set of timers has been directly implemented in the <code>trac</code> tool. In addition to the runtime for different parts of the code, estimates of memory usage and problem size are also reported.</p> <p>An example of output reported by the <code>trac</code> tool:</p> <pre><code>SIZE_NP = 10000\nSIZE_MPI_TASKS = 1\nSIZE_OMP_THREADS = 4\nMEMORY_ATM = 1449.58 MByte\nMEMORY_CACHE = 648.499 MByte\nMEMORY_CLIM = 15.3182 MByte\nMEMORY_METEO = 7408.74 MByte\nTIMER_ALLOC = 0.000 s    (min= 6.9767e-05 s, mean= 6.9767e-05 s, max= 6.9767e-05 s, n= 1)\nTIMER_READ_CTL = 0.007 s    (min= 0.00717609 s, mean= 0.00717609 s, max= 0.00717609 s, n= 1)\nTIMER_READ_CLIM = 0.025 s    (min= 0.0254529 s, mean= 0.0254529 s, max= 0.0254529 s, n= 1)\nTIMER_READ_ATM = 0.028 s    (min= 0.0275215 s, mean= 0.0275215 s, max= 0.0275215 s, n= 1)\nTIMER_MODULE_TIMESTEPS_INIT = 0.002 s    (min= 0.002085 s, mean= 0.002085 s, max= 0.002085 s, n= 1)\nTIMER_GET_MET = 0.026 s    (min= 1.546e-06 s, mean= 1.76945e-05 s, max= 0.00997372 s, n= 1444)\nTIMER_READ_MET_GRID = 0.003 s    (min= 0.000771007 s, mean= 0.000873196 s, max= 0.000986955 s, n= 4)\nTIMER_READ_MET_SURFACE = 0.219 s    (min= 0.0519605 s, mean= 0.0547709 s, max= 0.0580699 s, n= 4)\nTIMER_READ_MET_LEVELS = 5.490 s    (min= 1.30604 s, mean= 1.37255 s, max= 1.39654 s, n= 4)\nTIMER_READ_MET_EXTRAPOLATE = 0.253 s    (min= 0.0239204 s, mean= 0.06324 s, max= 0.103068 s, n= 4)\nTIMER_READ_MET_POLAR_WINDS = 0.006 s    (min= 0.00125896 s, mean= 0.00153137 s, max= 0.00172609 s, n= 4)\nTIMER_READ_MET_PERIODIC = 0.002 s    (min= 0.000341735 s, mean= 0.000458583 s, max= 0.000582423 s, n= 4)\nTIMER_READ_MET_GEOPOT = 1.594 s    (min= 0.394668 s, mean= 0.398482 s, max= 0.402873 s, n= 4)\nTIMER_READ_MET_PV = 0.238 s    (min= 0.0565131 s, mean= 0.0594941 s, max= 0.0644101 s, n= 4)\nTIMER_READ_MET_PBL = 0.122 s    (min= 0.0269698 s, mean= 0.0306072 s, max= 0.0331155 s, n= 4)\nTIMER_READ_MET_TROPO = 0.737 s    (min= 0.183587 s, mean= 0.184353 s, max= 0.18602 s, n= 4)\nTIMER_READ_MET_CLOUD = 0.085 s    (min= 0.0204375 s, mean= 0.0213186 s, max= 0.0221769 s, n= 4)\nTIMER_READ_MET_CAPE = 2.116 s    (min= 0.517294 s, mean= 0.528923 s, max= 0.549389 s, n= 4)\nTIMER_READ_MET_OZONE = 0.122 s    (min= 0.020632 s, mean= 0.0305517 s, max= 0.041007 s, n= 4)\nTIMER_MODULE_CHEM_INIT = 0.000 s    (min= 0.000247314 s, mean= 0.000247314 s, max= 0.000247314 s, n= 1)\nTIMER_MODULE_TIMESTEPS = 0.302 s    (min= 2.6811e-05 s, mean= 0.000209307 s, max= 0.000455049 s, n= 1441)\nTIMER_MODULE_POSITION = 0.629 s    (min= 5.9016e-05 s, mean= 0.000218254 s, max= 0.000583772 s, n= 2882)\nTIMER_MODULE_ADVECT = 1.685 s    (min= 0.000162452 s, mean= 0.00116961 s, max= 0.00311676 s, n= 1441)\nTIMER_MODULE_DIFF_TURB = 1.742 s    (min= 0.000707676 s, mean= 0.00120864 s, max= 0.00243357 s, n= 1441)\nTIMER_MODULE_DIFF_MESO = 1.544 s    (min= 0.000488041 s, mean= 0.00107166 s, max= 0.00232684 s, n= 1441)\nTIMER_MODULE_CONVECTION = 0.962 s    (min= 0.000295857 s, mean= 0.000667748 s, max= 0.00142307 s, n= 1441)\nTIMER_MODULE_METEO = 0.014 s    (min= 0.00228027 s, mean= 0.0035394 s, max= 0.00568389 s, n= 4)\nTIMER_MODULE_BOUND_COND = 0.916 s    (min= 4.1641e-05 s, mean= 0.000317876 s, max= 0.000974128 s, n= 2882)\nTIMER_MODULE_DECAY = 0.427 s    (min= 0.000157237 s, mean= 0.000296458 s, max= 0.000618609 s, n= 1441)\nTIMER_MODULE_MIXING = 2.408 s    (min= 0.0298906 s, mean= 0.0329851 s, max= 0.0553491 s, n= 73)\nTIMER_MODULE_CHEM_GRID = 1.744 s    (min= 0.000420581 s, mean= 0.00121059 s, max= 0.00318095 s, n= 1441)\nTIMER_MODULE_OH_CHEM = 1.873 s    (min= 0.000114869 s, mean= 0.00129959 s, max= 0.00288309 s, n= 1441)\nTIMER_MODULE_H2O2_CHEM = 0.776 s    (min= 5.8315e-05 s, mean= 0.00053884 s, max= 0.00215969 s, n= 1441)\nTIMER_MODULE_TRACER_CHEM = 2.582 s    (min= 1.9956e-05 s, mean= 0.00179167 s, max= 0.0040358 s, n= 1441)\nTIMER_MODULE_WET_DEPO = 0.532 s    (min= 1.9342e-05 s, mean= 0.000369044 s, max= 0.000838083 s, n= 1441)\nTIMER_MODULE_DRY_DEPO = 0.453 s    (min= 2.7147e-05 s, mean= 0.000314659 s, max= 0.000882621 s, n= 1441)\nTIMER_WRITE_ATM = 0.192 s    (min= 0.0456917 s, mean= 0.0480724 s, max= 0.049666 s, n= 4)\nTIMER_WRITE_GRID = 0.328 s    (min= 0.0776646 s, mean= 0.0819251 s, max= 0.0879495 s, n= 4)\nTIMER_WRITE_CSI = 1.025 s    (min= 0.000456732 s, mean= 0.000711579 s, max= 0.00215784 s, n= 1441)\nTIMER_WRITE_ENS = 0.003 s    (min= 0.000652666 s, mean= 0.000704509 s, max= 0.000817902 s, n= 4)\nTIMER_WRITE_PROF = 5.827 s    (min= 0.000380689 s, mean= 0.0040439 s, max= 0.0294752 s, n= 1441)\nTIMER_WRITE_SAMPLE = 0.024 s    (min= 9.81003e-07 s, mean= 1.65024e-05 s, max= 0.0191332 s, n= 1441)\nTIMER_WRITE_STATION = 0.620 s    (min= 0.000347288 s, mean= 0.000430191 s, max= 0.00285026 s, n= 1441)\nTIMER_WRITE_VTK = 0.152 s    (min= 0.0374231 s, mean= 0.0378852 s, max= 0.0385151 s, n= 4)\nTIMER_FREE = 0.098 s    (min= 0.0981576 s, mean= 0.0981576 s, max= 0.0981576 s, n= 1)\nTIMER_GROUP_MEMORY = 0.098 s\nTIMER_GROUP_INPUT = 5.798 s\nTIMER_GROUP_PHYSICS = 18.593 s\nTIMER_GROUP_METPROC = 5.276 s\nTIMER_GROUP_OUTPUT = 8.171 s\nTIMER_TOTAL = 37.936 s\n</code></pre> <p><code>SIZE_NP</code> refers to the number of particles used in the simulation. <code>SIZE_MPI_TASKS</code> refers to the number of MPI tasks. <code>SIZE_OMP_THREADS</code> refers to the number of OpenMP threads per MPI task. <code>SIZE_ACC_DEVICES</code> refers to the number of GPU devices per MPI task.</p> <p>The memory requirements have been derived by analyzing the data structures used in the code and are not based on measurements.</p> <p>Some timers are zero or not shown because the corresponding modules have not been used in this run.</p> <p>A simple optimization of memory requirements (and runtime!) is to adjust the constants <code>EX</code>, <code>EY</code>, and <code>EP</code>, defined in <code>mptrac.h</code>, to match the grid dimensions of the meteorological data set and the constant <code>NP</code> to match the number of particles used in the simulation.</p>"},{"location":"profiling/#profiling-of-cpu-runs","title":"Profiling of CPU runs","text":"<p>CPU profiling of MPTRAC is enabled using <code>gprof</code>. Set <code>PROF = 1</code> in the Makefile, recompile the code, and run a test case.</p> <p>Runtime information will be collected in the file <code>gmon.out</code> in the working directory. Use <code>gprof [binary]</code> to see the runtime profile.</p> <p>Example output for the <code>trac</code> tool:</p> <pre><code>Flat profile:\nEach sample counts as 0.01 seconds.\n  %   cumulative   self              self     total           \n time   seconds   seconds    calls  ms/call  ms/call  name    \n 27.09      2.85     2.85 21071464     0.00     0.00  intpol_met_space_3d\n 15.49      4.48     1.63       96    16.98    17.61  write_output\n  8.27      5.35     0.87     7770     0.11     0.68  frame_dummy\n  7.13      6.10     0.75 11636847     0.00     0.00  intpol_met_time_3d\n  5.04      6.63     0.53                             gomp_team_barrier_wait_end\n  4.56      7.11     0.48                             cspline_eval\n  3.33      7.46     0.35  2357631     0.00     0.00  clim_tropo\n  3.33      7.81     0.35                             __cos_avx\n  3.04      8.13     0.32                             __printf_fp_l\n  2.57      8.40     0.27                             gsl_ran_gaussian_ziggurat\n  2.28      8.64     0.24  3977062     0.00     0.00  intpol_met_space_2d\n  2.28      8.88     0.24        3    80.00    80.00  spline\n  2.09      9.10     0.22                             __mpn_divrem\n  1.71      9.28     0.18                             gomp_barrier_wait_end\n  1.62      9.45     0.17  7475552     0.00     0.00  locate_irr\n  1.05      9.56     0.11  2658144     0.00     0.00  intpol_met_time_2d\n  ...\n</code></pre>"},{"location":"profiling/#profiling-of-gpu-runs","title":"Profiling of GPU runs","text":"<p>GPU profiling is enabled by means of NVIDIA Nsight Systems. To see NVTX markers in the timeline, set <code>NVTX = 1</code> in the Makefile before compilation.</p> <p>Here is an example of how to enable Nsight Systems profiling in a job script:</p> <pre><code>    #### Nsight Systems notes                                                                                                                                                                                            \n    # For MPI profiling add \"mpi\" to the trace list:                                                                                                                                                                    \n    #     --trace=nvtx,osrt,openacc,mpi                                                                                                                                                                                     \n    # to start profiling after x sec add \"--delay x\":                                                                                                                                                                   \n    #     nsys profile -o wodiff --delay 5 ...      starts after 5 sec                                                                                                                                               \n    # To limit the profiling to x sec add \"--duration x\":                                                                                                                                                               \n    #     nsys profile -o wodiff --delay 7 ...      limits the profiling to 7 sec                                                                                                                                    \n\n    # Calculate trajectories...                                                                                                                                                                     \n    nsys profile -f true -o wodiff --trace=nvtx,osrt,openacc --stats=true \\\n        $trac/trac data/dirlist trac.ctl atm_split.tab meteo/ei ATM_BASENAME atm | tee data/log_trac.txt\n</code></pre> <p>After the execution, you can visualize <code>.qdrep</code>-files in <code>nsys-ui</code>. Refer to the Nsight Systems manual for other useful options.</p>"},{"location":"profiling/#further-reading","title":"Further reading","text":"<ul> <li> <p>gprof manual</p> </li> <li> <p>Nsight Systems documentation</p> </li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":"<p>A simple example is provided, illustrating how to simulate the dispersion of volcanic ash from the eruption of the Puyehue-Cord\u00f3n Caulle volcano, Chile, in June 2011.</p>"},{"location":"quickstart/#example-of-an-mptrac-simulation","title":"Example of an MPTRAC simulation","text":"<p>The example can be found in the <code>projects</code> directory. The <code>projects</code> directory can also be used to store results of other simulation and experiments with MPTRAC. The simulation is controlled by a shell script:</p> <pre><code>cd mptrac/projects/example\n./run.sh\n</code></pre> <p>Please see the script <code>run.sh</code> on how to invoke MPTRAC programs such as <code>atm_init</code> and <code>atm_split</code> to initialize trajectory seeds and <code>trac</code> to calculate the trajectories.</p> <p>The script generates a number of plots of the simulation output at different time steps after the eruption by means of the <code>gnuplot</code> graphing tool. These plots should look similar to the output already provided in the repository.</p> <p>This is an example showing the particle output on 6th to 8th of June 2011:</p> <p></p>"},{"location":"quickstart/#additional-project-subdirectories","title":"Additional project subdirectories","text":"<p>In addition to the example simulation, MPTRAC provides several utility scripts and resources in the <code>projects/</code> directory to support your work:</p> <ul> <li> <p><code>projects/meteo/</code>: Contains scripts for downloading meteorological input data from various data centers (e.g., ECMWF, NOAA), which are required for trajectory simulations.</p> </li> <li> <p><code>projects/python/</code>: Includes Python scripts to read, analyze, and visualize MPTRAC output data, such as air parcel trajectories and gridded fields. These can be helpful for creating custom plots and diagnostics.</p> </li> <li> <p><code>projects/paraview/</code>: Provides examples and guidelines for using ParaView to visualize MPTRAC air parcel data in an interactive 3D environment.</p> </li> </ul> <p>These directories offer helpful tools and examples for extending your use of MPTRAC beyond the basic workflow and adapting it to your specific research needs.</p>"},{"location":"quickstart/#further-information","title":"Further information","text":"<p>More detailed information for new users and developers of MPTRAC is provided in the user manual, the Doxygen manual, and in the GitHub wiki.</p> <p>For an in-depth description of the MPTRAC model, including its architecture, features, and GPU-based performance optimization, please refer to the following publication:</p> <p>Hoffmann, L., Baumeister, P. F., Cai, Z., Clemens, J., Griessbach, S., G\u00fcnther, G., Heng, Y., Liu, M., Haghighi Mood, K., Stein, O., Thomas, N., Vogel, B., Wu, X., and Zou, L.: Massive-Parallel Trajectory Calculations version 2.2 (MPTRAC-2.2): Lagrangian transport simulations on graphics processing units (GPUs), Geosci. Model Dev., 15, 2731\u20132762, https://doi.org/10.5194/gmd-15-2731-2022, 2022.</p> <p>A concise overview and introduction to MPTRAC is available in this open-access article:</p> <p>Hoffmann, L., Clemens, J., Griessbach, S., Haghighi Mood, K., Heng, Y., Khosrawi, F., Liu, M., Lu, Y.-S., Meyer, C., Nobre Wittwer, N., Wu, X., Zou, L., MPTRAC: A high-performance Lagrangian transport model for atmospheric air parcel dispersion, Journal of Open Source Software, 10(111), 8177, https://doi.org/10.21105/joss.08177, 2025.</p> <p>For a complete list of related publications and references, please visit the MPTRAC references page.</p> <p>We are interested in sharing MPTRAC for operational and research applications. Please do not hesitate to contact us, if you have any further questions or need support.</p>"},{"location":"references/","title":"References","text":"<p>These are the main references for citing the MPTRAC model in scientific publications:</p> <ul> <li> <p>Hoffmann, L., Clemens, J., Griessbach, S., Haghighi Mood, K., Heng,   Y., Khosrawi, F., Liu, M., Lu, Y.-S., Meyer, C., Nobre Wittwer, N.,   Wu, X., Zou, L., MPTRAC: A high-performance Lagrangian transport   model for atmospheric air parcel dispersion, Journal of Open Source   Software, 10(111), 8177, https://doi.org/10.21105/joss.08177,   2025.</p> </li> <li> <p>Hoffmann, L., Baumeister, P. F., Cai, Z., Clemens, J., Griessbach,   S., G\u00fcnther, G., Heng, Y., Liu, M., Haghighi Mood, K., Stein, O.,   Thomas, N., Vogel, B., Wu, X., and Zou, L.: Massive-Parallel   Trajectory Calculations version 2.2 (MPTRAC-2.2): Lagrangian   transport simulations on graphics processing units (GPUs),   Geosci. Model Dev., 15, 2731\u20132762,   https://doi.org/10.5194/gmd-15-2731-2022, 2022.</p> </li> <li> <p>Hoffmann, L., T. R\u00f6\u00dfler, S. Griessbach, Y. Heng, and O. Stein,   Lagrangian transport simulations of volcanic sulfur dioxide   emissions: Impact of meteorological data products,   J. Geophys. Res. Atmos., 121, 4651-4673,   https://doi.org/10.1002/2015JD023749, 2016.</p> </li> <li> <p>You can cite the source code of MPTRAC by using the DOI   https://doi.org/10.5281/zenodo.4400597. This DOI represents all   versions of MPTRAC, and will always resolve to the latest   one. Specific DOIs for each release of MPTRAC can be found on the   Zenodo web site.</p> </li> </ul> <p>This is a list of papers and theses in which MPTRAC was applied:</p> <ul> <li> <p>Huang, M. and Heng, Y.: Supercomputing-based inverse identification   of high-resolution atmospheric pollutant source intensity   distributions in High-Performance Computing and Artificial   Intelligence in Process Engineering, IOP Publishing, Bristol, UK,   https://dx.doi.org/10.1088/978-0-7503-6174-3ch10, 2025.</p> </li> <li> <p>Liu, M., Chemistry modeling and inverse reconstruction of emissions   with a Lagrangian transport model, Dissertation, Bergische   Universit\u00e4t Wuppertal, Wuppertal,   https://doi.org/10.25926/BUW/0-799, 2025</p> </li> <li> <p>Liu, M., Hoffmann, L., Groo\u00df, J.-U., Cai, Z., Grie\u00dfbach, S., and   Heng, Y.: Technical note: A comparative study of chemistry schemes   for volcanic sulfur dioxide in Lagrangian transport simulations \u2013 a   case study of the 2019 Raikoke eruption, Atmos. Chem. Phys., 25,   4403\u20134418, https://doi.org/10.5194/acp-25-4403-2025, 2025.</p> </li> <li> <p>Zhang, S., Wright, J. S., and Lu, M., A generalized Lagrangian   attribution tool for hydrometeorological extremes, Journal of   Geophysical Research: Atmospheres, 130, e2025JD043314,   https://doi.org/10.1029/2025JD043314, 2025.</p> </li> <li> <p>Clemens, J. H., Multi-scenario, high-resolution Lagrangian transport   modeling for the analysis of the Asian tropopause aerosol layer,   Dissertation, Bergische Universit\u00e4t Wuppertal, Wuppertal,   https://doi.org/10.25926/BUW/0-796, 2024.</p> </li> <li> <p>Clemens, J., Hoffmann, L., Vogel, B., Grie\u00dfbach, S., and Thomas, N.:   Implementation and evaluation of diabatic advection in the   Lagrangian transport model MPTRAC 2.6, Geosci. Model Dev., 17,   4467\u20134493, https://doi.org/10.5194/gmd-17-4467-2024, 2024.</p> </li> <li> <p>Clemens, J., Vogel, B., Hoffmann, L., Griessbach, S., Thomas, N.,   Fadnavis, S., M\u00fcller, R., Peter, T., and Ploeger, F.: A   multi-scenario Lagrangian trajectory analysis to identify source   regions of the Asian tropopause aerosol layer on the Indian   subcontinent in August 2016, Atmos. Chem. Phys., 24, 763\u2013787,   https://doi.org/10.5194/acp-24-763-2024, 2024.</p> </li> <li> <p>Hoffmann, L., Haghighi Mood, K., Herten, A., Hrywniak, M., Kraus,   J., Clemens, J., and Liu, M.: Accelerating Lagrangian transport   simulations on graphics processing units: performance optimizations   of Massive-Parallel Trajectory Calculations (MPTRAC) v2.6,   Geosci. Model Dev., 17, 4077\u20134094,   https://doi.org/10.5194/gmd-17-4077-2024, 2024.</p> </li> <li> <p>Liao, Y., Deng, X., Huang, M., Liu, M., Yi, J., and Hoffmann, L.,   Tracking Carbon Dioxide with Lagrangian Transport Simulations: Case   Study of Canadian Forest Fires in May 2021, Atmosphere, 15, 429,   https://doi.org/10.3390/atmos15040429, 2024.</p> </li> <li> <p>Zou, L., Spang, R., Griessbach, S., Hoffmann, L., Khosrawi, F.,   M\u00fcller, R., and Tritscher, I.: A statistical analysis of the   occurrence of polar stratospheric ice clouds based on MIPAS   satellite observations and the ERA5 reanalysis, EGUsphere   [preprint], https://doi.org/10.5194/egusphere-2024-547, 2024.</p> </li> <li> <p>Hoffmann, L., Konopka, P., Clemens, J., and Vogel, B.: Lagrangian   transport simulations using the extreme convection parameterization:   an assessment for the ECMWF reanalyses, Atmos. Chem. Phys., 23,   7589\u20137609, https://doi.org/10.5194/acp-23-7589-2023, 2023.</p> </li> <li> <p>Liu, M., Hoffmann, L., Griessbach, S., Cai, Z., Heng, Y., and Wu,   X.: Improved representation of volcanic sulfur dioxide depletion in   Lagrangian transport simulations: a case study with MPTRAC v2.4,   Geosci. Model Dev., 16, 5197\u20135217,   https://doi.org/10.5194/gmd-16-5197-2023, 2023.</p> </li> <li> <p>Wu, X., Qiao, Q., Chen, B., Wang, X., Hoffmann, L., Griessbach, S.,   Tian, Y., and Wang, Y., The influence of the Asian summer monsoon on   volcanic aerosol transport in the UTLS region, npj   Clim. Atmos. Sci., 6, 11,   https://doi.org/10.1038/s41612-023-00339-w, 2023.</p> </li> <li> <p>Cai, Z., Griessbach, S., and Hoffmann, L.: Improved estimation of   volcanic SO2 injections from satellite retrievals and Lagrangian   transport simulations: the 2019 Raikoke eruption,   Atmos. Chem. Phys., 22, 6787\u20136809,   https://doi.org/10.5194/acp-22-6787-2022, 2022.</p> </li> <li> <p>Hoffmann, L. and Spang, R.: An assessment of tropopause   characteristics of the ERA5 and ERA-Interim meteorological   reanalyses, Atmos. Chem. Phys., 22, 4019\u20134046,   https://doi.org/10.5194/acp-22-4019-2022, 2022.</p> </li> <li> <p>Mishra, M.K., Hoffmann, L., Thapliyal, P.K.: Investigations on the   Global Spread of the Hunga Tonga-Hunga Ha\u2019apai Volcanic Eruption   Using Space-Based Observations and Lagrangian Transport   Simulations. Atmosphere, 13, 2055,   https://doi.org/10.3390/atmos13122055, 2022.</p> </li> <li> <p>Smoydzin, L. and Hoor, P.: Contribution of Asian emissions to upper   tropospheric CO over the remote Pacific, Atmos. Chem. Phys., 22,   7193\u20137206, https://doi.org/10.5194/acp-22-7193-2022, 2022.</p> </li> <li> <p>Liu, M., Huang, Y., Hoffmann, L., Huang, C., Chen, P., Heng, Y.:   High-Resolution Source Estimation of Volcanic Sulfur Dioxide   Emissions Using Large-Scale Transport Simulations, in:   Krzhizhanovskaya V.V. et al. (eds), Computational Science \u2013 ICCS   2020, ICCS 2020, Lecture Notes in Computer Science, vol 12139,   Springer, https://doi.org/10.1007/978-3-030-50420-5_5, 2020.</p> </li> <li> <p>Zhang, J., Wu, X., Bian, J., Xia, X., Bai, Z., Liu, Y., Cai, Z.,   Huo, J., Lyu, D., Aerosol variations in the upper troposphere and   lower stratosphere over the Tibetan Plateau. Environ. Res. Lett.,   15(9), 094068,   https://iopscience.iop.org/article/10.1088/1748-9326/ab9b43, 2020.</p> </li> <li> <p>Hoffmann, L., G\u00fcnther, G., Li, D., Stein, O., Wu, X., Griessbach,   S., Heng, Y., Konopka, P., M\u00fcller, R., Vogel, B., and Wright, J. S.:   From ERA-Interim to ERA5: the considerable impact of ECMWF's   next-generation reanalysis on Lagrangian transport simulations,   Atmos. Chem. Phys., 19, 3097-3124,   https://doi.org/10.5194/acp-19-3097-2019, 2019.</p> </li> <li> <p>R\u00f6\u00dfler, T., Stein, O., Heng, Y., Baumeister, P., and Hoffmann, L.:   Trajectory errors of different numerical integration schemes   diagnosed with the MPTRAC advection module driven by ECMWF   operational analyses, Geosci. Model Dev., 11, 575-592,   https://doi.org/10.5194/gmd-11-575-2018, 2018.</p> </li> <li> <p>Wu, X., Griessbach, S., and Hoffmann, L.: Long-range transport of   volcanic aerosol from the 2010 Merapi tropical eruption to   Antarctica, Atmos. Chem. Phys., 18, 15859-15877,   https://doi.org/10.5194/acp-18-15859-2018, 2018.</p> </li> <li> <p>Hoffmann, L., Hertzog, A., R\u00f6\u00dfler, T., Stein, O., and Wu, X.:   Intercomparison of meteorological analyses and trajectories in the   Antarctic lower stratosphere with Concordiasi superpressure balloon   observations, Atmos. Chem. Phys., 17, 8045-8061,   https://doi.org/10.5194/acp-17-8045-2017, 2017.</p> </li> <li> <p>Wu, X., Griessbach, S., and Hoffmann, L.: Equatorward dispersion of   a high-latitude volcanic plume and its relation to the Asian summer   monsoon: a case study of the Sarychev eruption in 2009,   Atmos. Chem. Phys., 17, 13439-13455,   https://doi.org/10.5194/acp-17-13439-2017, 2017.</p> </li> <li> <p>Heng, Y., Hoffmann, L., Griessbach, S., R\u00f6\u00dfler, T., and Stein, O.:   Inverse transport modeling of volcanic sulfur dioxide emissions   using large-scale simulations, Geosci. Model Dev., 9, 1627-1645,   https://doi.org/10.5194/gmd-9-1627-2016, 2016.</p> </li> </ul>"},{"location":"tropopause-data/","title":"Tropopause data","text":"<p>This page provides information on the methods used to calculate and extract tropopause data with MPTRAC.</p>"},{"location":"tropopause-data/#determination-of-the-tropopause","title":"Determination of the tropopause","text":"<p>In general, the tropopause data in MPTRAC are calculated from the given meteorological input data, i.e, the data are not read from the meteo data files.</p> <p>For the determination of the height level of the tropopause, the meteorological data are first interpolated to a fine vertical grid by means of cubic spline interpolation. The tropopause level is estimated based on the interpolated data. This approach improves the vertical resolution of the tropopause data. However, the vertical resolution of the meteorological input data will also play an important role.</p> <p>The method used to extract the height level of the tropopause is selected by means of the parameter <code>MET_TROPO</code>. The following options to determine the tropopause level have been implemented:</p> MET_TROPO Description 0 no tropopause is calculated 1 use NCEP/NCAR Reanalysis-1 monthly mean zonal mean climatology 2 extract the cold point (temperature minimum along the vertical profile) 3 (default) use WMO definition based on thermal lapse rate 4 extract location of the WMO second tropopause 5 use dynamical definition (3.5 PVU in the extratropics and 380 K in the tropics)"},{"location":"tropopause-data/#tropopause-data-along-trajectories","title":"Tropopause data along trajectories","text":"<p>The <code>trac</code> tool of MPTRAC can extract the tropopause data along the trajectories. For example, set the following quantities to obtain tropopause pressure, height, and temperature:</p> <pre><code>    NQ = 3\n    QNT_NAME[0] = pt   # tropopause pressure [hPa]\n    QNT_NAME[1] = zt   # tropopause geootential height [km]\n    QNT_NAME[2] = tt   # tropopause temperature [K]\n</code></pre>"},{"location":"tropopause-data/#tropopause-data-files","title":"Tropopause data files","text":"<p>MPTRAC provides the tool <code>tropo</code> that generates tropopause data files from given meteorological input data.</p> <p>The tropopause data are provided as netCDF files. Each data file may contain one or more time steps of the reanalysis.</p> <p>The data files provide geopotential height, pressure, temperature, and water vapor volume mixing ratios for the cold point, WMO first and second tropopause, and the dynamical tropopause.</p> <p>The tool <code>tropo_sample</code> can be used to extract tropopause data from the netCDF files created by <code>tropo</code> for a set of locations specified as a particle data file (<code>atm.tab</code> file).</p> <p>Tropopause data files for various meteorological reanalyses generated with MPTRAC can be found in the Reanalysis Tropopause Data Repository.</p>"},{"location":"tropopause-data/#references","title":"References","text":"<ul> <li> <p>WMO tropopause definition</p> </li> <li> <p>NCEP/NCAR Reanalysis-1</p> </li> </ul>"},{"location":"apps/atm_conv/","title":"atm_conv","text":"<p><code>atm_conv</code> converts atmosphere files from one format into the other. Possible input files are ASCII, binary, netcdf and netcdf files following format guidelines for CLaMS. The data can be converted to these files as well. The usage is as follows:</p> <pre><code># calling atm_conv\n$ ./atm_conv  &lt;ctl&gt; &lt;atm_in&gt; &lt;atm_type_in&gt; &lt;atm_out&gt; &lt;atm_type_out&gt;\n</code></pre> <ul> <li><code>ctl</code> : The control file is used to set the atmospheric types and files if not set in the command line. It is also needed if it is empty. </li> <li><code>atm_in</code>: Input atmospheric file</li> <li><code>atm_type_in</code>: Format of input atmospheric file</li> <li><code>atm_out</code>: Output atmospheric file</li> <li><code>atm_type_in</code>: Format of output atmospheric file</li> </ul> <p>The type of data can be chosen from the options below:</p> ATM_TYPE output format 0 ASCII (default) 1 binary 2 netcdf 3 netcdf (CLaMS: trajectory and position file) 4 netcdf (CLaMS: position file) <p>Note:  If trajectory files similar to those of CLaMS are required (<code>atm_type=3</code>), the stop time, as seen below, must be set in the control file. However, to obtain position files as for CLaMS the option <code>atm_type=4</code>, which does not rely on these setting, is recommended instead.</p> <pre><code>cat &gt; atm_conv.ctl &lt;&lt;EOF\nT_STOP = 360547200.00          \nEOF   \n</code></pre> <p>Example: </p> <p><code>atm_conv atm_conv.ctl input.tab 0 output.nc 2</code></p> <p>, converts the input.tab ASCII file into the new &gt; netcdf file output.nc.</p>"},{"location":"apps/atm_dist/","title":"atm_dist","text":"<p>This application calculates the transport deviations of trajectories.</p> <p>atm_dist can be called by:</p> <pre><code># calling atm_dist\n$ ./atm_dist  &lt;ctl&gt; &lt;dist.tab&gt; &lt;param&gt; &lt;atm1a&gt; &lt;atm1b&gt; [&lt;atm2a&gt; &lt;atm2b&gt; ...]\n</code></pre> <p>The required arguments to run atm_dist are as follows: * ctl: is the control (.ctl) file of the trajectory simulation  dist.tab: the output file where the deviations should be written into  param: the deviation paramters to be calculated (e.g. abs_dev etc. see below) * atm1a and atm1b: the trajectory files that should be compared</p> <p>Statistical paramters that can be calculated are:</p> <ul> <li>mean</li> <li>stddv</li> <li>min</li> <li>max</li> <li>skew</li> <li>kurt</li> <li>absdev</li> <li>median</li> <li>mad</li> </ul> <p>The here used statistics are the gnu statistic library. More information on the gnu statistics library can be found on their webpage. </p> <p>An example command line for running atm_dist looks like as follows:</p> <pre><code>./atm_dist trac.ctl dist_absdev.tab abs_dev traj_sim1_2017_01_01_00.tab traj_sim2_2017_01_01_00.tab\n</code></pre> <p>Note: The command line needs to be adjusted to the respective directories were the files (or executables in case of atm_dist) are located. </p> <p>Additional paramters that can be used when running atm_dist are:</p> <p>DIST_LAT0 -89 DIST_LAT1 89  - The latitude range to be considered   DIST_Z0 8 DIST_Z1 16 - The altitude range to be considered  DISTZCORE - can be used for filtering outliers  </p>"},{"location":"apps/atm_init/","title":"atm_init","text":"<p>The application atm_init creates an atmospheric data file with initial air parcel positions. The code will generate air parcels in a simple manner with user-defined settings.</p> <pre><code># calling atm_init\n$ ./atm_init  &lt;ctl&gt; &lt;atm_out&gt;\n</code></pre> <p>The following specific configuration parameters can be used to determine the release position:</p> parameter purpose default INIT_T0 Release time range start [s] 0 INIT_T1 Release time range end [s] 0 INIT_DT Release time interval [s] 1 INIT_Z0 Release altitude range start [km] 0 INIT_Z1 Release altitude range end [km] 0 INIT_DZ Release altitude interval [km] 1 INIT_LON0 Release longitude range start 0 INIT_LON1 Release longitude range end 0 INIT_DLON Release longitude interval 1 INIT_LAT0 Release latitude range start 0 INIT_LAT1 Release latitude range end 0 INIT_DLAT Release latitude interval 1 <p>Followings are some optional parameters for controlling the release of air parcels:</p> <ul> <li>INIT_REP: This parameter controls the number of air parcels in each release position. The default value is 1.</li> <li>INIT_MASS: Total release mass [kg]. The default value is 0.</li> <li>INIT_VMR: Volume mixing ratio of each air parcel [ppv]. The default value is 0.</li> <li>INIT_ST/INIT_SZ/INIT_SLON/INIT_SLAT: If this parameter is set to non-zero value, the air parcels are released with a Gaussian distribution in time/altitude/longitude/latitude. The parameter value represents the full width at half maximum. </li> <li>INIT_UT/INIT_UZ/INIT_ULON/INIT_ULAT: If this parameter is set to non-zero value, the air parcels are released with a uniform distribution in time/altitude/longitude/latitude. The parameter value represents release range.</li> <li>INIT_EVENLY: If this parameter is set to 1, the number of air parcels released will be weighted by the cosine of latitude so that the air parcels are evenly distributed globally.</li> <li>INIT_IDX_OFFSET: Offset value added to air parcel indices. This parameter allows customization of the starting index for air parcels, which can be useful for domain decomposition or when combining multiple initialization runs. The default value is 0. </li> </ul> <p>Note: Instead of using the control file the configuration parameters can also be appended to the function call. </p>"},{"location":"apps/atm_select/","title":"atm_select","text":"<p>Extract subsets of air parcels from atmospheric data files.</p> <p>The calling sequence is:</p> <pre><code># calling atm_select\n$ atm_select  &lt;ctl&gt; &lt;atm_select&gt; &lt;atm1&gt; [&lt;atm2&gt; ...]\n</code></pre> <p>The atmospheric data file(s)  [ \u2026] contain(s) a list of data points with the structure: <pre><code>time altitude longitude latitude quantity_1 quantity_2 ...\n</code></pre> <p>Following the selection criteria provided in the control file  atm_select extracts a subset of the data points and writes them into a new atmospheric data file with the file name provided in . The following atm_select specific configuration parameters can be used: parameter purpose default SELECT_STRIDE select every i-th data point 1 SELECT_IP0 set index range start 0 SELECT_IP1 set index range end 0 SELECT_T0 set time range start [s] 0 SELECT_T1 set time range end [s] 0 SELECT_Z0 set altitude range start [km] 0 SELECT_Z1 set altitude range end [km] 0 SELECT_LON0 set longitude range start [deg] 0 SELECT_LON1 set longitude range end [deg] 0 SELECT_LAT0 set latitude range start [deg] 0 SELECT_LAT1 set latitude range end [deg] 0 SELECT_R0 set radius range start [km] 0 SELECT_R1 set radius range end [km] 0 SELECT_RLON set station longitude [deg] 0 SELECT_RLAT set station latitude [deg] 0 <p>The parameters should be given as an indexed list in the control file (example).</p>"},{"location":"apps/atm_split/","title":"atm_split","text":"<p>Split air parcels into a larger number of parcels.</p> <p>The calling sequence is:</p> <pre><code># calling atm_split\n$ ./atm_split  &lt;ctl&gt; &lt;atm_in&gt; &lt;atm_out&gt;\n</code></pre> <p>The atmospheric input data file  contains a list of data points with the structure: <pre><code>time altitude longitude latitude quantity_1 quantity_2 ...\n</code></pre> <p>Based on the locations provided in the input atmospheric data file  atm_split generates a specified total number of data points by generating new data points in a region defined by the configuration parameters and stores the result in a new atmospheric data file with the file name provided in . <p>The following atm_split specific configuration parameters can be used:</p> parameter purpose default SPLIT_N total number of data points to generate SPLIT_M total SO2 mass of all data points [] -999 SPLIT_DT delta time [s] 0 SPLIT_T0 time window start [s] 0 SPLIT_T1 time window end [s] 0 SPLIT_DZ vertical radius [km] 0 SPLIT_Z0 altitude range start [km] 0 SPLIT_Z1 altitude range end [km] 0 SPLIT_DX horizontal radius [km] 0 SPLIT_LON0 longitude range start 0 SPLIT_LON1 longitude range end; LON0&lt;LON1 0 SPLIT_LAT0 latitude range start 0 SPLIT_LAT1 latitude range end; LAT0&lt;LAT1 0 SPLIT_KERNEL kernel file name \u2013 <p>If a range is provided the data points are distributed uniformly. If a distance is provided (DT, DZ, DX), the data points are distributed with a Gaussian random variate where e.g. \u2018distance\u2019/2.3548 = FWHM.</p> <p>Note: Instead of using the control file the configuration parameters can also be appended to the function call. </p>"},{"location":"apps/atm_stat/","title":"atm_stat","text":"<p>Calculate air parcel statistics.</p> <p>```</p>"},{"location":"apps/atm_stat/#calling-atm_stat","title":"calling atm_stat","text":"<p>$ atm_stat    [ ...] ```` <p>Statistical paramters that can be calculated are:</p> <ul> <li>mean</li> <li>stddv</li> <li>min</li> <li>max</li> <li>skew</li> <li>kurt</li> <li>absdev</li> <li>median</li> <li>mad</li> </ul> <p>The here used statistics are the gnu statistic library. More information on the gnu statistics library can be found  on their webpage. </p>"},{"location":"apps/cape/","title":"cape","text":"<p>Add CAPE data to netCDF file. </p> <pre><code># Calling cape\n./ cape &lt;ctl&gt; &lt;met.nc&gt;\n</code></pre> <p>The required parameters are: * ctl: The control file. * met.nc: The data file into which cape should be added.</p>"},{"location":"apps/day2doy/","title":"day2doy","text":"<p>This application converts date (yyyy m dd) to day of the year.</p> <pre><code># calling day2doy\n$ day2doy  &lt;year&gt; &lt;mon&gt; &lt;day&gt;\n</code></pre> <p>In the following we exemplarily convert the 10 February 2017 to day:</p> <pre><code>$ ./day2doy 2017 02 10\n$ 2017 41\n</code></pre>"},{"location":"apps/doy2day/","title":"doy2day","text":"<p>This applications converts the day of a year to date (yyyy mm dd).</p> <pre><code># calling doy2day\n$ ./doy2day  &lt;year&gt; &lt;doy&gt;\n</code></pre> <p>In the following we exemplarily convert day 41 of the year 2017 to date:</p> <pre><code>$ ./doy2day 2017 41\n$ 2017 2 10\n</code></pre>"},{"location":"apps/jsec2time/","title":"jsec2time","text":"<p>This application converts Julian seconds to date.</p> <pre><code># calling jsec2time\n$ ./jsec2time &lt;jsec&gt;\n</code></pre> <p>Converting exemplarily Julian seconds of 539314401.00 after the 1. January 2000 in date results in:</p> <pre><code>./jsec2time 539314401.00\n2017 2 2 1 0 0 0 0.11\n</code></pre> <p>Thus, Julian seconds of 539314401.00 correspond to the 2 February 2017 at hour hour 1:00 (0 s and 0.11 ms).</p>"},{"location":"apps/met_conv/","title":"met_conv","text":"<p>Conversion of meteorological data</p> <pre><code># calling met_conv\n./met_conv &lt;ctl&gt; &lt;met_in&gt; &lt;met_in_type&gt; &lt;met_out&gt; &lt;met_out_type&gt;\n</code></pre> <p>The required paramters are as follows:</p> <ul> <li>ctl: The control file.</li> <li>met_in: The name of the meteorological file that should be converted.</li> <li>met_in_type: The format type of the meteorological input file.</li> <li>met_out: The name of the meteorological file in the new data format. </li> <li>met_out_type: The type into the meteorological data file should be converted.</li> </ul> <pre><code># An example command line for running met_conv looks like\n./met_conv trac.ctl era5_2017_01_08_17.nc 0 era5_2017_01_08_17.zstd 4\n</code></pre> <p>Here the meteorological data file in netcdf format is converted (compressed) to the zstd format.</p> <p>The following input/output files are supported by met_conv:</p> Type In/Out Format 0 netcdf 1 binary 2 pck 3 zfp 4 zstd <p>whereby netcdf and binary are standard data formats. Pck (layer packing, https://gmd.copernicus.org/articles/10/413/2017), zfp (https://computing.llnl.gov/projects/zfp) and zst (zstandard, https://github.com/facebook/zstd) are compression formats. </p> <p>Currently to enable the usage of zfp and zstd format MPTRAC needs to be compiled using ZSTD=1 and ZFP=1:</p> <p>```</p>"},{"location":"apps/met_conv/#run-make-enabling-the-usage-of-the-zfp-and-zstd-compression","title":"Run make enabling the usage of the ZFP and ZSTD compression","text":"<p>$ make ZSTD=1 ZFP=1 ````</p>"},{"location":"apps/met_map/","title":"met_map","text":"<p>Extracts map from meteorological data.</p> <pre><code># calling met_map\n$ ./met_map  &lt;ctl&gt; &lt;map.tab&gt; &lt;met0&gt; [&lt;met1&gt; ...]\n</code></pre> <p>The required parameters are as follows:</p> <ul> <li>ctl: The file containing the control parameters. The control parameters can also be appended at the end of the function call, giving the flag name first, followed by the parameter, all separated by a space.</li> <li>met_map: The output file in which the map should be stored.</li> <li>met0 [\\&lt;met1&gt; ...]: The meteorological data from which the climatology should be created.</li> </ul> <p>Note: The control parameters can also be appended to the function call, but they will cause error messages, as a loop runs over all input parameters &gt;= 3 and tries to read files named as the control parameters. Despite the annoying error messages the app will create a correct output file. </p> <p>Calling met_map and creating out of the 0.3\u00b0 x 0.3\u00b0 ERA5 data on a 1\u00b0 x 1\u00b0 map would look like as follows:</p> <pre><code># Calling met_map\n$./met_map - map_era5_2017_01_08_17_1_1.tab era5_2017_01_08_17.nc MAP_DLON 1 MAP_DLAT 1\n</code></pre> <p>The optional control parameters required are listed as follows:</p> parameter purpose default MAP_Z0 The altitude to extract the map data [km] 10 MAP_LON0 Longitude range start -180 MAP_LON1 Longitude range end 180 MAP_DLON Longitude interval -999 MAP_LAT0 Latitude range start -90 MAP_LAT1 Latitude range end 90 MAP_DLAT Latitude interval -999 MAP_THETA Use theta level instead of altitude -999 <p>To extract a map from a compressed data file (as e.g. a ZFP file) one would need to give also the meteorological data file format as control parameter. Calling met_map would then look as follows:</p> <pre><code># Calling met_map for a zfp file\n$./met_map - map_era5_2017_01_08_17.tab era5_2017_01_08_17.zfp MET_TYPE 3\n</code></pre> <p>Currently, to enable the usage of zfp and zstd format MPTRAC needs to be compiled using ZSTD=1 and ZFP=1:</p> <p>```</p>"},{"location":"apps/met_map/#run-make-enabling-the-usage-of-the-zfp-and-zstd-compression","title":"Run make enabling the usage of the ZFP and ZSTD compression","text":"<p>$ make ZSTD=1 ZFP=1 ````</p>"},{"location":"apps/met_prof/","title":"met_prof","text":"<p>Extract vertical profile from meteorological data.</p> <pre><code># calling met_prof\n$ ./met_prof  &lt;ctl&gt; &lt;prof.tab&gt; &lt;met0&gt; [&lt;met1&gt; ...]\n</code></pre> <p>The required arguments are:</p> <ul> <li>ctl: The file containing the control parameters.</li> <li>prof.tab: The output file in which the profile data should be stored.</li> <li>\\&lt;met0&gt; [\\&lt;met1&gt; ...]: The meteorological input data.</li> </ul> <p>Calling met_prof and creating a 1 km resolution verical profile from a global ERA5 data sample of 1\u00b0 x 1\u00b0 would look like as follows:</p> <pre><code># Calling met_map\n$./met_prof - prof_era5_2017_01_08_17_1_1.tab era5_2017_01_08_17.nc PROF_LON0 -180 PROF_LON1 180\\\n    PROF_LAT0 -90 PROF_LAT1 90 PROF_DLON 1 PROF_DLAT 1 PROF_Z0 0 PROF_Z1 25 PROF_DZ 1\n</code></pre> <p>The optional control parameters required are listed as follows:</p> parameter purpose default PROF_Z0 Altitude range start [km] -999 PROF_Z1 Altitude range end [km] -999 PROF_DZ Altitude interval [km] -999 PROF_LON0 Longitude range start 0 PROF_LON1 Longitude range end 0 PROF_DLON Longitude interval -999 PROF_LAT0 Latitude range start 0 PROF_LAT1 Latitude range end 0 PROF_DLAT Latitude interval -999"},{"location":"apps/met_sample/","title":"met_sample","text":"<p>Sample meteorological data at given geolocations </p> <pre><code># calling met_sample\n$ ./met_sample  &lt;ctl&gt; &lt;sample.tab&gt; &lt;atm_in&gt;\n</code></pre> <p>The required input parameters are: * ctl: The control file, defining the atmospheric grid. * sample.tab: Output ascii file with re-sampled meteorological data to the locations provided in atm_in. * atm_in: Input file of atm-type. Expected input parameters are a list of data sets containing time, altitude, longitude, and latitude.</p> <p>Add an example for  calling/applying met_sample.</p> <pre><code># Calling met_sample\n$./met_sample sample.ctl new_file.tab volcanoes.tab \n</code></pre> <p>The following configuration parameters are effective in met_sample:</p> parameter purpose default SAMPLE_GEOPOT sample geopotential height 0 SAMPLE_GRID_TIME sample time 0 SAMPLE_GRID_Z sample altitude 0 SAMPLE_GRID_LON sample longitude 0 SAMPLE_GRID_LAT sample latitude 0"},{"location":"apps/met_spec/","title":"met_spec","text":"<p>This app conducts a spectral analysis of the meteorological temperature fields using the fast Fourier transform method. It will provide estimates of zonal wave amplitude, wavelength, and phase as a function of pressure and latitude.</p> <pre><code>Calling met_spec\n./met_sepc &lt;ctl&gt; &lt;spec.tab&gt; &lt;met0&gt;\n</code></pre> <p>The required control parameters are: * ctl: the control parameter file * spec.tab: the output file (in form of an ASCII table) * met0: the metorological input file</p>"},{"location":"apps/met_subgrid/","title":"met_subgrid","text":"<p>Calculates the grid-scale standard deviations of the horizontal wind and vertical velocity fields as used in the subgrid-scale wind parameterization. The subgrid-scale wind parametrization is described in Stohl et al. (2005).</p> <ul> <li>Stohl, A., Forster, C., Frank, A., Seibert, P., and Wotawa, G.: Technical note: The Lagrangian particle dispersion model FLEXPART version 6.2, Atmos. Chem. Phys., 5, 2461\u20132474, https://doi.org/10.5194/acp-5-2461-2005, 2005. </li> </ul> <pre><code># calling met_subgrid\n$ ./met_subgrid  &lt;ctl&gt; &lt;subgrid.tab&gt; &lt;met0&gt; &lt;met1&gt; [ &lt;met0b&gt; &lt;met1b&gt; ... ]\n</code></pre> <p>The required control parameters are: * ctl: the control parameter file * subgrid.tab: the output file with standard deviations of the wind and velocity (in ASCII table format) * met*: pairs of meteorological data files from which the standard deviations are calculated</p>"},{"location":"apps/met_zm/","title":"met_zm","text":"<p>Extract zonal mean from meteorological data.</p> <p>The calling sequence is:</p> <pre><code># calling met_zm\n$ ./met_zm  &lt;ctl&gt; &lt;zm.tab&gt; &lt;met0&gt; [&lt;met1&gt; ...]\n</code></pre> <p>The required arguments are: * ctl: The file containing the control parameters. * zm.tab: The output file where the zonal means are stored. * met0 [\\&lt;met1&gt; ...]: The meteorological input files from which the zonal mean should be calculatd from.</p> <p>Calling met_zm and creating a global zonal mean data with latitude band of 10 degree from ERA5 data would look like as follows:</p> <pre><code># Calling met_zm\n$./met_prof - zm_era5_2017_01_08_17_1_1.tab era5_2017_01_08_17.nc \\\n    ZM_DLAT 10  \n</code></pre> <p>The optional control parameters required are listed as follows:</p> parameter purpose default ZM_Z0 Altitude range start [km] -999 ZM_Z1 Altitude range end [km] -999 ZM_DZ Altitude interval [km] -999 ZM_LON0 Longitude range start -180 ZM_LON1 Longitude range end 180 ZM_LAT0 Latitude range start -90 ZM_LAT1 Latitude range end 90 ZM_DLAT Latitude interval -999 <p>Note: if ZM_DZ, ZM_Z0, ZM_Z1 are not defined, the output dimension of altitude will follow the meteorological data.</p>"},{"location":"apps/sedi/","title":"sedi","text":"<p>This application calculates the sedimentation velocity \\(v_s\\) (in units of m/s) of aerosol or cloud particles for a given particle radius \\(r_p\\) and particle density \\(\\rho_p\\). In MPTRAC, \\(v_s\\) is calculated for spherical particles following the method described by Jacobson (1999). Sedimentation velocities are valid for particle Reynolds number \\(Re_p \\le 1\\), for which \\(v_s\\) is expected to have accuracies better than 10\u2009% (Hesketh, 1996). Larger particles will require additional corrections, which have not been implemented. See Hoffmann et al. (2022, Sect. 2.3.5) for further details.</p> <ul> <li>Jacobson, M. Z.: Fundamentals of Atmospheric Modeling, Cambridge University Press, https://doi.org/10.1017/CBO9781139165389, 1999.</li> <li>Hesketh, H. E. (Ed.): Air Pollution Control: Traditional Hazardous Pollutants, Revised Edition, CRC Press, ISBN 9781566764131, 1996.</li> <li>Hoffmann, L., Baumeister, P. F., Cai, Z., Clemens, J., Griessbach, S., G\u00fcnther, G., Heng, Y., Liu, M., Haghighi Mood, K., Stein, O., Thomas, N., Vogel, B., Wu, X., and Zou, L.: Massive-Parallel Trajectory Calculations version 2.2 (MPTRAC-2.2): Lagrangian transport simulations on graphics processing units (GPUs), Geosci. Model Dev., 15, 2731\u20132762, https://doi.org/10.5194/gmd-15-2731-2022, 2022.</li> </ul> <pre><code># calling sedi\n$./sedi &lt;p&gt; &lt;T&gt; &lt;r_p&gt; &lt;rho_p&gt;\n</code></pre> <p>The required control parameters are: * p: Pressure in hPa * T: Temperature in K * r_p: particle radius in micrometers * rho_p: particle density in kg/m^3</p>"},{"location":"apps/time2jsec/","title":"time2jsec","text":"<p>Given a date and time this app returns the Julian seconds since 01.01.2000.</p> <pre><code># calling time2jsec\n$ ./time2jsec  &lt;year&gt; &lt;month&gt; &lt;day&gt; &lt;hour&gt; &lt;minute&gt; &lt;second&gt; &lt;remain&gt;\n</code></pre> <p>The required arguments are: * year: The year, e.g. 2020. * month: Valid parameters for month are 1\u201312. * day: Valid values for day are 1\u201331. * hour: Valid values for hour are 0\u201323.* * minute: Valid values for minute are 0\u201359. * second: Valid values for second are 0\u201359. * remain: Can be used add milliseconds, e.g. 0.111. If this value is set to 1, a second is added.</p> <p>Note: This app also accepts values outside the valid value range whithout any warning. </p>"},{"location":"apps/tnat/","title":"tnat","text":"<p>This application calculates the PSC formation temperatures (in Kelvin).</p> <pre><code># Calling tnat\n$./tnat &lt;p&gt; &lt;h2o&gt; &lt;hno3&gt;\n</code></pre> <p>Required paramters are: * p: The atmospheric pressure in hPa. * h2o: The volume mixing ratio (ppv) of water vapour. * hno3: The volume mixing ratio (ppv)  of sulfuric acid.</p> <p>Assuming a pressure of 50 hPa and a H<sub>2</sub>O volume mixing ratio of 5 ppmv and a HNO<sub>3</sub> mixing ratio of 15 ppbv: </p> <pre><code>$./tnat 50 5e-6 15e-9\n</code></pre> <p>one receives the following ouput:</p> <pre><code>$ p = 50 hPa\n$ q_H2O = 5e-06 ppv\n$ q_HNO3 = 1.5e-08 ppv\n$ T_dew = 184.543 K\n$ T_ice = 188.559 K\n$ T_NAT = 196.312 K\n</code></pre>"},{"location":"apps/trac/","title":"trac","text":"<p>The major app for calculating forward or backward trajectories is trac. It is called with at least four (4) arguments:</p> <pre><code># calling trac\n$ ./trac  &lt;dirlist&gt; &lt;ctl&gt; &lt;atm_in&gt; &lt;metbase&gt;\n</code></pre> <p>The required arguments are:</p> <ul> <li> <p>dirlist: A file containing directories to be processed. Each directory has to have an own control parameter file and a starting point file.</p> </li> <li> <p>ctl: In the control parameter file the configuration parameters can be set.</p> </li> <li> <p>atm_in: The starting point file contains a list of starting points for the trajectory calculation.</p> </li> <li> <p>metbase: Here, the path to the meteorological data files and their basename shall be given.</p> </li> </ul> <p>Example from the repository:</p> <pre><code># minimal required input to run trac\n$ ./trac data/dirlist trac.ctl atm_split.tab meteo/ei\n</code></pre> <p>In addition it is possible to append control parameters, giving the flag name first, followed by the parameter, all separated by a space. Example:</p> <pre><code>#\n$ ./trac data/dirlist trac.ctl atm_split.tab meteo/ei ATM_BASENAME atm_diff GRID_BASENAME grid_diff\n</code></pre> <p>The following control parameters are effective in trac:</p> <p>Todo</p> <p>add flaglist here \u2026. </p> <p>A full list can be found in the doxygen manual.</p> <p>Note: However, in the doxygen are so far no default values etc. provided.</p>"},{"location":"apps/tropo/","title":"tropo","text":"<p>This application creates a tropopause data set from meteorological data.</p> <pre><code># calling tropo\n$ ./tropo  &lt;ctl&gt; &lt;tropo.nc&gt; &lt;met0&gt; [&lt;met1&gt; ...]\n</code></pre> <p>The required arguments are: * ctl: The file containing the control parameters. * tropo.nc: The output file in which the climatology should be stored. * met0 [\\&lt;met1&gt; ...]: The meteorological data from which the data set should be created.</p> <p>The following paramerters can be defined in &lt;.ctl&gt; file: | parameter  | description                                    | default | Options                                            | |:---------- |:---------------------------------------------- | ------- | -------------------------------------------------- | | DT_MET     | time step of meteorological data [s].          | 21600   |                                                    | | MET_TROPO  | tropopause definition                          | 3       | 0:none, 1:clim, 2:cold point, 3:WMO_1ST, 4:WMO_2nd, 5:dynamical | | MET_TROPO_PV | dynamical tropopause threshold (PV)          | 3.5     | | TROPO_LON0 | minimum longitude                              | -180    |                                                    | | TROPO_LON1 | maximum longitude                              | 180     |                                                    | | TROPO_DLON | distance between longitudes                    | -999    |                                                    | | TROPO_LAT0 | minimum latitude                               | -90     |                                                    | | TROPO_LAT1 | maximum latitude                               | 90      |                                                    | | TROPO_DLAT | distance between latitudes                     | -999    |                                                    | | TROPO_H2O  | extract water vapor mixing ratio at tropopause | 1       |                                                    | | TROPO_O3   | extract ozone volume at tropopause             | 1       |                                                    | |            |                                                |         |                                                    |</p> <p>Example:</p> <pre><code># define the control file\ncat &gt; tropo.ctl &lt;&lt;EOF\nDT_MET = 21600  \nMET_TROPO = 2\nTROPO_DLON = 6\nTROPO_DLAT = 3\nEOF\n# running the tropo application\n../src/tropo tropo.ctl tropo_2011_06_05.nc ../ei_2011_06_05_00.nc ../ei_2011_06_06_00.nc\n</code></pre> <p>here: * ../src/tropo: calling tropo * tropo.ctl: using control file * tropo_2011_06_05.nc: output of the tropopause  * ../ei_...: inputs of the meteorological data (data directory should be indicated) * At JSC, Era_interim data can be found: /p/fastdata/slmet/slmet111/met_data/ecmwf/era_interim/pressure_0.75deg_v2/nc/2011/ei_...nc</p>"},{"location":"apps/tropo_sample/","title":"tropo_sample","text":"<p>Sample the tropopause height from tropopause data file  created by e.g. tropo at a given time, latitude, and longitude provided in the atmosphere data file . The tropopause data files may contain snapshots at a certain time or climatologies. The results in terms of tropopause geometric height, pressure, temperature, and water vapour volume mixing ratio are written to the tropopause sample output file . <pre><code># calling tropo_sample\n$ tropo_sample  &lt;ctl&gt; &lt;sample.tab&gt; &lt;tropo.nc&gt; &lt;var&gt; &lt;atm_in&gt;\n</code></pre> <p>The type of tropopause information to be extracted is selected with the \\&lt;var&gt; argument. The following options are provided by the data files generated by tropo:</p> parameter description 0 none 1 climatology 2 cold point tropopause 3 WMO first lapse rate tropopause 4 WMO second lapse rate tropopause 5 dynamical tropopause <p>The following configuration parameters are effective in tropo_sample:</p> parameter purpose default TROPO_SAMPLE_METHOD Define interpolation method. Default=1: linear interpolation. Everything else: nearest neighbor. 1"},{"location":"apps/tropo_zm/","title":"tropo_zm","text":"<p>This application extracts the zonal mean of a tropopause data set.</p> <pre><code># Calling tropo_zm\n./tropo_zm &lt;ctl&gt; &lt;zm.tab&gt; &lt;var&gt; &lt;tropo.nc&gt;\n</code></pre> <p>The required parameters are: * ctrl: The file containing the control parameters. * zm.tab: The ouput file in which the zonal means should be stored. * var: The tropopause variables * tropo.nc: The tropopause data set of which the zonal means should be calculated.</p> var description clp cold point tropopause dyn dynamical tropopause wmo_1st WMO first lapse rate tropopause wmo_2nd WMO secon lapse rate tropopause <p>Example:</p> <pre><code>for var in clp dyn wmo_1st wmo_2nd ; do\n    ../src/tropo_zm - zm_$var.tab $var tropo_2011_06_05.nc\ndone\n</code></pre> <p>Here: * ../src/tropo_zm: calling tropo_zm * no control file is given * zm_$var.tab: output of the zonal mean tropopause with the same latitude as the input data * tropo_2011_06_05.nc: input, the tropopause dataset produced by \"tropo\"</p> <p>output: * $1 = time [s] * $2 = latitude [deg] * $3 = tropopause height (mean) [km] * $4 = tropopause pressure (mean) [hPa] * $5 = tropopause temperature (mean) [K] * $6 = tropopause water vapor (mean) [ppv] * $7 = tropopause ozone (mean) [ppv] * $8 = tropopause height (sigma) [km] * $9 = tropopause pressure (sigma) [hPa] * $10 = tropopause temperature (sigma) [K] * $11 = tropopause water vapor (sigma) [ppv] * $12 = tropopause ozone (sigma) [ppv] * $13 = number of data points * $14 = occurrence frequency [%]</p>"},{"location":"apps/wind/","title":"wind","text":"<p>This app creates a meteorological data file with synthetic wind fields suitable for testing advection using the method of Williamson et al. (1992, Sect. 3). The synthetic wind field describes a global rotation around the Earth with a given rotation axis. The output is written in form of MPTRAC's netCDF meteo file format.</p> <ul> <li>Williamson, D. L., Drake, J. B., Hack, J. J., Jakob, R., &amp; Swarztrauber, P. N. (1992). A standard test set for numerical approximations to the shallow water equations in spherical geometry. Journal of computational physics, 102(1), 211-224.</li> </ul> <pre><code># Calling wind\n$ ./wind &lt;ctl&gt; &lt;metbase&gt;\n</code></pre> <p>The required parameters are: * ctl: the control parameter file * metbase: the basename of the output file</p> <p>Optional control parameters: * WIND_T0: time step of meteo data (default: 0 s) * WIND_NX: number of longitudes (default: 360) * WIND_NY: number of latitudes (default: 181) * WIND_NZ: number of pressure levels (default: 61) * WIND_Z0: log-pressure height of lowermost pressure level (default: 0 km) * WIND_Z1: log-pressure height of uppermost pressure level (default: 60 km) * WIND_U0: horizontal wind speed at lowermost level (default: 38.587660177302 m/s) * WIND_U1: horizontal wind speed at uppermost level (default: 38.587660177302 m/s) * WIND_W0: vertical velocity (default: 0 m/s) * WIND_ALPHA: rotation angle (default: 0 deg) * WIND_LAT_REVERSE: latitude direction flag (default: 0, set to 1 for reversed latitude direction)</p>"}]}